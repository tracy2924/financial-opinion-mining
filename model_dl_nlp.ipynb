{"cells":[{"cell_type":"markdown","source":["**DL and contextual word embeddings**"],"metadata":{"id":"8nB1UZStw-GZ"}},{"cell_type":"markdown","source":["These codes are main adopted from https://github.com/bentrevett/pytorch-sentiment-analysis"],"metadata":{"id":"KQvlryjQwo8H"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"jU4fWKs_wmWl"},"outputs":[],"source":["import torch\n","import numpy as np\n","import random\n","SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division\n","    acc = correct.sum() / len(correct)\n","    return acc"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"n_EpaHuGwmWn"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import torch.nn as nn\n","\n","class BiLSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","                 bidirectional, dropout, pad_idx):\n","\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n","\n","        self.rnn = nn.LSTM(embedding_dim,\n","                           hidden_dim,\n","                           num_layers=n_layers,\n","                           bidirectional=bidirectional,\n","                           dropout=dropout)\n","\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, text, text_lengths):\n","\n","        #text = [sent len, batch size]\n","\n","        embedded = self.dropout(self.embedding(text))\n","\n","        #embedded = [sent len, batch size, emb dim]\n","\n","        #pack sequence\n","        # lengths need to be on CPU!\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n","\n","        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n","\n","        #unpack sequence\n","        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n","\n","        #output = [sent len, batch size, hid dim * num directions]\n","        #output over padding tokens are zero tensors\n","\n","        #hidden = [num layers * num directions, batch size, hid dim]\n","        #cell = [num layers * num directions, batch size, hid dim]\n","\n","        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","        #and apply dropout\n","\n","        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","\n","        #hidden = [batch size, hid dim * num directions]\n","\n","        return self.fc(hidden)\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"P705b-wtwmWo"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import torch.nn.functional as F\n","\n","class CNN1d(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim,\n","                 dropout, pad_idx):\n","\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n","\n","        self.convs = nn.ModuleList([\n","                                    nn.Conv1d(in_channels = embedding_dim,\n","                                              out_channels = n_filters,\n","                                              kernel_size = fs)\n","                                    for fs in filter_sizes\n","                                    ])\n","\n","        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, text):\n","\n","        #text = [batch size, sent len]\n","\n","        embedded = self.embedding(text)\n","\n","        #embedded = [batch size, sent len, emb dim]\n","\n","        embedded = embedded.permute(0, 2, 1)\n","\n","        #embedded = [batch size, emb dim, sent len]\n","\n","        conved = [F.relu(conv(embedded)) for conv in self.convs]\n","\n","        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n","\n","        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n","\n","        #pooled_n = [batch size, n_filters]\n","\n","        cat = self.dropout(torch.cat(pooled, dim = 1))\n","\n","        #cat = [batch size, n_filters * len(filter_sizes)]\n","\n","        return self.fc(cat)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"UjEBENT0wmWp"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["class BiGRU(nn.Module):\n","    \"\"\"BiDirectional GRU neural network model.\n","    \"\"\"\n","\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","                 bidirectional, dropout, pad_idx):\n","\n","        # Inherit everything from the nn.Module\n","        super(BiGRU, self).__init__()\n","\n","        # Initialize layers\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim,padding_idx=pad_idx)\n","\n","        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=n_layers,\n","                          dropout=dropout,\n","                          bidirectional=bidirectional)\n","\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, text, text_lengths):\n","        \"\"\"Forward propagate through the neural network model.\n","\n","        Returns\n","        -------\n","        torch.Tensor\n","            Logarithm of softmaxed input tensor.\n","\n","        \"\"\"\n","        #text = [sent len, batch size]\n","        embedded = self.dropout(self.embedding(text))\n","        #embedded = [sent len, batch size, emb dim]\n","        ## Output: (batch_size, seq_length, embedding_dim)\n","\n","        #pack sequence\n","        # lengths need to be on CPU!\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n","\n","        packed_output, hidden = self.gru(packed_embedded)\n","\n","        #unpack sequence\n","        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n","        #output = [sent len, batch size, hid dim * num directions]\n","        #output over padding tokens are zero tensors\n","\n","        #hidden = [num layers * num directions, batch size, hid dim]\n","\n","        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","        #and apply dropout\n","\n","        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","\n","        #hidden = [batch size, hid dim * num directions]\n","\n","        return self.fc(hidden)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Pnp74UHxwmWq"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"919UCWz8wmWr"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def train(model, iterator, optimizer, criterion, include_lengths):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in iterator:\n","\n","        optimizer.zero_grad()\n","\n","        if include_lengths:\n","            text, text_lengths = batch.text\n","            predictions = model(text, text_lengths).squeeze(1)\n","\n","        else:\n","            predictions = model(batch.text).squeeze(1)\n","\n","        loss = criterion(predictions, batch.label)\n","\n","        acc = binary_accuracy(predictions, batch.label)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"sKZvYYhtwmWr"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def evaluate(model, iterator, criterion, include_lengths):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","\n","            if include_lengths:\n","                text, text_lengths = batch.text\n","                predictions = model(text, text_lengths).squeeze(1)\n","\n","            else:\n","                predictions = model(batch.text).squeeze(1)\n","\n","            loss = criterion(predictions, batch.label)\n","\n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"8tOOfRVHwmWs"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def predict(model, iterator, include_lengths):\n","    y_predict=[]\n","    y_predict_prob=[]\n","    y_test=[]\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for batch in iterator:\n","            if include_lengths:\n","                text, text_lengths = batch.text\n","                predictions = model(text, text_lengths).squeeze(1)\n","\n","            else:\n","                predictions = model(batch.text).squeeze(1)\n","\n","            pred_prob=torch.sigmoid(predictions)\n","            rounded_preds = torch.round(pred_prob)\n","            y_predict += rounded_preds.tolist()\n","            y_predict_prob += pred_prob.tolist()\n","            y_test += batch.label.tolist()\n","    return np.asarray(y_predict), np.asarray(y_predict_prob), np.asarray(y_test)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"E8YE_LtqwmWs"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"1VccNPdjwmWt"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from sklearn.metrics import matthews_corrcoef,accuracy_score,f1_score,precision_score,recall_score\n","def get_evaluation_metrics(y_true,y_pred):\n","    metrics_dict=dict()\n","    metrics_dict['accuracy']=accuracy_score(y_true,y_pred)\n","    metrics_dict['precision']=precision_score(y_true,y_pred)\n","    metrics_dict['recall']=recall_score(y_true,y_pred)\n","    metrics_dict['f1']=f1_score(y_true,y_pred)\n","    metrics_dict['matthews_corr']=matthews_corrcoef(y_true,y_pred)\n","    return metrics_dict"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"tpSWlbgcwmWt"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["evaluation_dict=dict()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"M-45XAY3wmWt"}},{"cell_type":"markdown","source":["**BiLSTM & BiGRU**"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"F5Y-WCmowmWu"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from torchtext.legacy import data\n","import os\n","current_p=os.getcwd()\n","file_p=os.path.join(current_p,'Reddit Data')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"VtYRPA9jwmW7"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from torchtext.legacy import data\n","TEXT = data.Field(sequential=True, include_lengths=True)\n","LABEL = data.LabelField(dtype = torch.float, use_vocab=False,preprocessing=int)\n","\n","fields={'Label_encode':('label',LABEL),'Tokens':('text',TEXT)}"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"r8WsVtPRwmW8"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import os\n","current_p=os.getcwd()\n","file_p=os.path.join(current_p,'Reddit Data')\n","train_data,valid_data,test_data=data.TabularDataset.splits(\n","    path=file_p,\n","    train='train.json',\n","    validation='valid.json',\n","    test='test.json',\n","    format='json',\n","    fields=fields\n",")"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"WwZhT1_rwmW8"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': 1, 'text': ['thank', 'wsb', 'member', 'rememb', 'hold', 'die', 'ride', 'dawn', 'happi', 'trade', 'slv', 'gme', 'amc', 'nok']}\n"]}],"source":["print(vars(test_data.examples[30]))"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"MREh1vO0wmW8","outputId":"437b5f2e-9a0f-4937-d90a-6bbe4c34d49a"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': 1, 'text': ['hold', 'line', 'rocket', 'gem_ston', 'rocket', 'gem_ston', 'rocket', 'gem_ston', 'rocket']}\n"]}],"source":["print(vars(train_data.examples[30]))"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"FnUylgJqwmW9","outputId":"7f7a53a6-677c-4f1b-f9f5-b3de37d58e40"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': 0, 'text': ['fella', \"y'all\", 'come', 'back', 'get', 'gme']}\n"]}],"source":["print(vars(valid_data.examples[30]))"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"wUQ-N4HqwmW-","outputId":"4294ebe2-2869-4996-da6e-de7425432a5d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import torchtext.vocab as vocab\n","\n","w2v_embeddings = vocab.Vectors(name = 'Reddit Data/Word2Vec/GoogleNews_w2vec.txt',\n","                               cache = 'Reddit Data/Word2Vec',\n","                               unk_init = torch.Tensor.normal_)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"tuuumP8vwmW-"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["TEXT.build_vocab(train_data,vectors=w2v_embeddings)\n","LABEL.build_vocab(train_data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Crjh2QKCwmW-"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"'<pad>'"},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.pad_token"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"1KZ9iBorwmW-","outputId":"eedc371b-2a70-4842-a897-7fb13a518228"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"tensor([ 0.1032, -1.6268,  0.5729, -0.6995, -0.8748,  2.2994, -1.4453, -0.7350,\n        -1.3636,  0.3067, -1.0327,  1.3824,  1.1538, -0.5540, -0.8932, -0.3465,\n         1.0827, -1.0121, -0.2642,  0.2560, -0.6692, -2.3203,  0.5021, -0.1246,\n        -0.6560, -0.7049, -1.1843, -0.2645, -2.7675,  1.4802,  0.2942,  1.3924,\n        -0.4910, -0.9858, -0.5375, -1.7054, -1.2253, -0.6665, -0.5090, -0.5193,\n         0.4593, -0.6748, -0.1634, -0.7026,  0.5690,  0.4715,  0.4616, -1.3822,\n         0.6241,  0.9364,  0.7707, -0.1255, -0.0446, -0.2705,  1.1501,  1.4566,\n        -0.0417,  0.7463,  0.3322, -0.1859, -1.4301, -1.4317,  2.1155, -1.1853,\n        -0.3650,  0.4927, -0.5866,  0.7948, -0.5345,  2.2011, -1.2147, -0.8642,\n        -0.0450,  1.3279, -0.6276, -0.3739, -2.0552,  0.7384,  0.9454, -1.3522,\n        -0.3972,  0.4209,  0.1005, -0.6588, -1.3583, -0.1869, -1.3208,  1.4487,\n        -0.9434, -0.8170,  0.3422, -1.0809, -0.4060,  0.2415,  0.2559, -0.0605,\n        -0.8933, -0.2504,  0.2037, -0.6473, -0.4815, -0.8533,  0.2310,  0.7535,\n         0.8086, -0.9196, -1.1723,  0.4238,  0.4891, -0.5015,  1.6710, -0.8182,\n         0.9377, -0.4547, -0.3017, -0.1081, -0.7839,  2.1911,  0.3531,  0.8087,\n        -0.1217,  0.7741, -2.4929, -0.4774, -0.5434,  1.1363,  0.7060,  0.5937,\n        -0.0959,  0.9456, -1.2708,  0.2959,  0.1503,  1.1833, -0.7282, -1.2537,\n        -0.0732, -0.0150,  0.1451,  0.2020,  0.2722,  0.2987,  0.4729, -0.4718,\n        -0.9389,  0.8857,  1.3764, -0.7828,  0.2220,  0.0738,  1.0746,  0.7868,\n         1.1427, -1.0126,  0.1160, -1.0350,  1.0803, -0.7998, -0.8772, -1.0245,\n        -0.4517, -0.4807,  0.5907,  0.1634, -0.0314,  0.4465,  1.4797, -1.0431,\n         1.4661,  0.6120,  0.7994,  0.9301,  1.2819, -0.6290,  0.7272, -1.4299,\n        -2.1502,  0.4151,  0.0032, -0.3858,  0.5768, -1.1972,  0.2659, -0.7091,\n         1.1415, -0.4416,  0.3492, -1.6730,  1.7173, -1.0184, -2.1019, -1.6981,\n         0.1733, -0.6813,  0.0256,  1.2838,  1.3107,  1.4736, -0.2851, -0.3726,\n        -1.7115, -0.8005,  1.4921, -0.1077,  1.8001,  0.9789, -0.4627, -1.4979,\n         0.0752,  0.8398,  1.3866, -0.9521, -0.4907, -1.4583,  0.3990,  0.3334,\n         1.2403,  0.8706, -0.7415,  1.7150,  0.5972,  0.1110,  0.7745, -0.6644,\n        -0.4375, -0.4464, -0.7372,  0.0616, -0.2503, -0.1452,  1.3390, -2.4515,\n        -0.8078,  1.6439, -1.2366,  0.0595, -0.1399,  0.0665, -2.0364, -0.4900,\n        -0.0522,  1.0433, -0.1780,  0.5411,  1.5247, -0.0229, -1.1519, -0.3090,\n        -1.1722, -0.3579,  2.7906, -0.1816,  0.5197, -0.3198, -0.6821,  0.2706,\n        -0.2876,  1.0301,  0.7295,  0.1031,  0.2796,  1.2181,  0.1727,  0.2069,\n        -1.0222, -1.1600,  0.7207,  0.1496, -0.8315, -1.9167, -0.3378, -0.8732,\n         0.0223, -1.4754,  0.4335, -0.2378,  0.3429, -2.3405, -0.8842, -0.3780,\n        -0.3906,  0.0974,  1.0617,  1.2896,  0.9495, -1.1080, -1.1848, -1.4867,\n        -1.1119, -0.5569, -0.1938,  0.6627,  0.6738,  0.1218,  1.5987,  0.4411,\n         1.3639,  0.3180, -0.1626, -0.0417])"},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.vectors[TEXT.vocab.stoi['<pad>']]"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"iW6uheoRwmW_","outputId":"e63c4962-ecf4-464b-96c4-78f2316bfbc4"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"torch.Size([35807, 300])"},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.vectors.shape"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"u-v65DNqwmW_","outputId":"5a499398-224b-4e2f-d73f-a24ce732d12d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["BATCH_SIZE = 32\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    sort_key = lambda x: len(x.text),\n","    sort_within_batch = True,\n","    device = device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"oyvC0rD9wmW_"}},{"cell_type":"markdown","source":["BiLSTM"],"metadata":{"collapsed":false,"id":"XupYHQSkwmW_"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 300\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 10\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = BiLSTM(INPUT_DIM,\n","            EMBEDDING_DIM,\n","            HIDDEN_DIM,\n","            OUTPUT_DIM,\n","            N_LAYERS,\n","            BIDIRECTIONAL,\n","            DROPOUT,\n","            PAD_IDX)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"R-_P4Gy9wmXA"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 26,078,037 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"qJvebTjRwmXA","outputId":"8c9d7d90-29b9-4e52-ae17-902962bd05c8"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([35807, 300])\n"]}],"source":["pretrained_embeddings = TEXT.vocab.vectors\n","print(pretrained_embeddings.shape)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"v14dCjOFwmXA","outputId":"67efb9f5-c9b1-4e25-cac9-156aafddc091"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.4447,  0.8402, -0.8668],\n        [ 0.1032, -1.6268,  0.5729,  ...,  0.3180, -0.1626, -0.0417],\n        [-0.0320,  0.2715, -0.2891,  ...,  0.1562, -0.3906, -0.1592],\n        ...,\n        [ 1.2594,  0.5802, -0.6321,  ..., -0.3219, -0.9991,  0.6622],\n        [ 0.8923,  1.2147,  0.5376,  ...,  0.2644,  0.3166, -1.5350],\n        [ 0.1721, -1.1185,  0.2176,  ...,  0.1322,  0.4259, -1.0902]])"},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["model.embedding.weight.data.copy_(pretrained_embeddings)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"_7qz2DYnwmXB","outputId":"0307f6e4-5ae2-4e3f-e9d8-4156ec03bc36"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.0320,  0.2715, -0.2891,  ...,  0.1562, -0.3906, -0.1592],\n","        ...,\n","        [ 1.2594,  0.5802, -0.6321,  ..., -0.3219, -0.9991,  0.6622],\n","        [ 0.8923,  1.2147,  0.5376,  ...,  0.2644,  0.3166, -1.5350],\n","        [ 0.1721, -1.1185,  0.2176,  ...,  0.1322,  0.4259, -1.0902]])\n"]}],"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","print(model.embedding.weight.data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"yqQ5i1prwmXB","outputId":"4dc336a0-be42-4c22-ae26-4bba148e5bf4"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 26,078,037 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"qz_U0M7swmXB","outputId":"dd6bd9ca-0ea2-42c8-db22-5c052f04e050"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["#Train model\n","import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters(),lr=1e-3)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"7dTD71ZTwmXC"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.691 | Train Acc: 52.96%\n","\t Val. Loss: 0.693 |  Val. Acc: 69.25%\n","Epoch: 02 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.685 | Train Acc: 54.03%\n","\t Val. Loss: 0.631 |  Val. Acc: 63.09%\n","Epoch: 03 | Epoch Time: 1m 27s\n","\tTrain Loss: 0.592 | Train Acc: 69.32%\n","\t Val. Loss: 0.593 |  Val. Acc: 59.29%\n","Epoch: 04 | Epoch Time: 1m 26s\n","\tTrain Loss: 0.533 | Train Acc: 73.95%\n","\t Val. Loss: 0.512 |  Val. Acc: 51.19%\n","Epoch: 05 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.490 | Train Acc: 76.76%\n","\t Val. Loss: 0.501 |  Val. Acc: 50.13%\n","Epoch: 06 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.465 | Train Acc: 78.24%\n","\t Val. Loss: 0.502 |  Val. Acc: 50.17%\n","Epoch: 07 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.445 | Train Acc: 79.38%\n","\t Val. Loss: 0.495 |  Val. Acc: 49.55%\n","Epoch: 08 | Epoch Time: 1m 26s\n","\tTrain Loss: 0.427 | Train Acc: 80.45%\n","\t Val. Loss: 0.503 |  Val. Acc: 50.33%\n","Epoch: 09 | Epoch Time: 1m 23s\n","\tTrain Loss: 0.411 | Train Acc: 81.40%\n","\t Val. Loss: 0.514 |  Val. Acc: 51.35%\n","Epoch: 10 | Epoch Time: 1m 23s\n","\tTrain Loss: 0.394 | Train Acc: 82.19%\n","\t Val. Loss: 0.500 |  Val. Acc: 50.03%\n","Epoch: 11 | Epoch Time: 1m 24s\n","\tTrain Loss: 0.382 | Train Acc: 82.87%\n","\t Val. Loss: 0.530 |  Val. Acc: 52.96%\n","Epoch: 12 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.366 | Train Acc: 83.71%\n","\t Val. Loss: 0.531 |  Val. Acc: 53.07%\n","Epoch: 13 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.356 | Train Acc: 84.49%\n","\t Val. Loss: 0.553 |  Val. Acc: 55.28%\n","Epoch: 14 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.345 | Train Acc: 84.93%\n","\t Val. Loss: 0.531 |  Val. Acc: 53.11%\n","Epoch: 15 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.335 | Train Acc: 85.49%\n","\t Val. Loss: 0.536 |  Val. Acc: 53.60%\n","Epoch: 16 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.327 | Train Acc: 85.93%\n","\t Val. Loss: 0.557 |  Val. Acc: 55.75%\n","Epoch: 17 | Epoch Time: 1m 24s\n","\tTrain Loss: 0.323 | Train Acc: 86.21%\n","\t Val. Loss: 0.576 |  Val. Acc: 57.59%\n","Epoch: 18 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.317 | Train Acc: 86.55%\n","\t Val. Loss: 0.578 |  Val. Acc: 57.81%\n","Epoch: 19 | Epoch Time: 1m 25s\n","\tTrain Loss: 0.310 | Train Acc: 86.81%\n","\t Val. Loss: 0.579 |  Val. Acc: 57.86%\n","Epoch: 20 | Epoch Time: 1m 24s\n","\tTrain Loss: 0.301 | Train Acc: 87.23%\n","\t Val. Loss: 0.587 |  Val. Acc: 58.75%\n"]}],"source":["N_EPOCHS = 20\n","\n","INCLUDE_LENGTHS=True\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion,INCLUDE_LENGTHS)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, INCLUDE_LENGTHS)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), './Reddit Data/model/w2vec_BiLSTMmodel.pt')\n","    #else:\n","        #break\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_loss*100:.2f}%')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"FldUf5G8wmXC","outputId":"7cac1f37-b07a-4e99-9fe7-194f1cf03f5d"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7557779947916666, 'precision': 0.7584140969162996, 'recall': 0.7253117627232896, 'f1': 0.741493668705315, 'matthews_corr': 0.5107346385905418}\n"]}],"source":["y_pred,y_pred_prob,y_true = predict(model,test_iterator,INCLUDE_LENGTHS)\n","metrics=get_evaluation_metrics(y_true,y_pred)\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"vdWU1hOZwmXC","outputId":"d155b0d3-0398-481d-fe8d-3fc33c015da3"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7661946614583334, 'precision': 0.7768131669379634, 'recall': 0.7237950792045837, 'f1': 0.7493675303149262, 'matthews_corr': 0.5319489220021474}\n"]}],"source":["model.load_state_dict(torch.load('./Reddit Data/model/w2vec_BiLSTMmodel.pt'))\n","y_pred,y_pred_prob,y_true = predict(model,test_iterator,INCLUDE_LENGTHS)\n","\n","metrics=get_evaluation_metrics(y_true,y_pred)\n","evaluation_dict['word2vec+BiLSTM']=[metrics,y_pred,y_pred_prob,y_true]\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"uyHIOLlzwmXD","outputId":"7ef5c8a5-8b5f-48c5-bc64-55d04b284665"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"{'word2vec+BiLSTM': [{'accuracy': 0.7661946614583334,\n   'precision': 0.7768131669379634,\n   'recall': 0.7237950792045837,\n   'f1': 0.7493675303149262,\n   'matthews_corr': 0.5319489220021474},\n  array([0., 0., 1., ..., 1., 1., 1.]),\n  array([0.25730208, 0.3950069 , 0.528404  , ..., 0.89427865, 0.97807616,\n         0.94837987]),\n  array([0., 0., 0., ..., 1., 1., 1.])]}"},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["evaluation_dict"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"vaHCfh9CwmXD","outputId":"8063a5fb-d27e-4c4e-a0a8-d09f91ade3df"}},{"cell_type":"markdown","source":["BiGRU"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"2M0oFw8ywmXD"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["TEXT = data.Field(sequential=True, include_lengths=True)\n","LABEL = data.LabelField(dtype = torch.float, use_vocab=False,preprocessing=int)\n","\n","fields={'Label_encode':('label',LABEL),'Tokens':('text',TEXT)}"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"9mFHZaaVwmXD"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["train_data,valid_data,test_data=data.TabularDataset.splits(\n","    path=file_p,\n","    train='train.json',\n","    validation='valid.json',\n","    test='test.json',\n","    format='json',\n","    fields=fields\n",")"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"FA2EkrzQwmXE"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["w2v_embeddings = vocab.Vectors(name = 'Reddit Data/Word2Vec/GoogleNews_w2vec.txt',\n","                               cache = 'Reddit Data/Word2Vec',\n","                               unk_init = torch.Tensor.normal_)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"iRDslpcBwmXE"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["TEXT.build_vocab(train_data, vectors=w2v_embeddings)\n","LABEL.build_vocab(train_data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"mKyDGMs_wmXE"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"'<pad>'"},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.pad_token"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"0fhGIjX3wmXE","outputId":"70fff79b-af72-4aae-8f58-6d90b7101f7d"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"tensor([ 0.2830, -0.0118,  2.8122,  0.0139, -2.1980,  0.4822,  0.5802,  0.4480,\n         2.1580, -0.7408, -0.5547,  0.4285, -1.4326,  1.8095,  0.6048, -0.0434,\n        -0.8797, -0.0246,  2.5886, -0.7145,  1.6420,  0.3631, -0.2524,  0.6571,\n         0.7801,  0.4597, -2.1794, -0.9077, -1.2133,  0.6321, -1.6600,  1.1422,\n        -0.0645, -0.6532,  0.3675, -0.3731, -0.7669, -0.9682,  0.3727,  1.4716,\n         0.5704, -0.4303, -1.5339,  0.7233, -0.7759,  1.7938,  1.2074, -1.2815,\n         0.6802, -0.0553,  0.8862, -0.3312,  0.4211,  0.7117, -0.6974,  1.5942,\n         1.1334,  0.3630,  0.9284,  0.2573, -0.2855,  1.0653, -0.4345,  0.7062,\n         0.7869,  0.4423,  0.1055, -0.9142,  1.0618,  1.7697, -0.4495, -0.7490,\n        -1.2562,  0.6927,  0.8468,  0.3769, -2.1307,  1.9362, -0.5090,  0.4294,\n        -0.3738,  0.1951,  0.9953,  1.1275, -2.8874, -0.8086, -0.5714,  0.5279,\n        -0.8257,  0.6465,  2.2281,  0.6334, -0.0557,  0.3232,  0.8646, -1.2108,\n        -1.5809, -1.5757, -0.3230, -0.3433,  1.5142, -0.3959,  0.6263, -0.7306,\n        -0.4256, -0.4925,  1.0075, -0.7721,  0.2631,  0.1544,  0.8181, -0.0315,\n        -0.8443,  0.5535, -1.6237,  0.9313, -1.2930,  0.2153, -0.6875, -0.1759,\n         0.6288, -1.3318,  0.9643, -0.6653, -0.7049,  1.8965, -1.4548, -1.3036,\n         0.4458,  0.6613,  0.2251, -1.5336, -1.4975,  2.0771, -0.2249,  0.0721,\n         1.0557,  0.8767, -1.9450, -0.1262, -0.7858, -1.3253, -0.2661, -2.3829,\n         1.1090,  0.8367,  0.2441,  1.2452,  1.1323,  0.8176,  1.3215,  0.2962,\n         1.0379, -0.5680, -0.2193, -2.0083,  0.0508,  1.6977,  0.7393,  0.0685,\n         0.4780,  0.2711,  0.5489,  0.0218, -0.4802, -1.4843, -0.0355,  2.6242,\n        -0.0463,  0.3724,  0.7773, -0.6762, -0.8126, -0.8181, -1.2466,  0.2790,\n         0.6173, -0.1017, -0.3450,  1.7355,  0.9873,  1.0612,  2.1093, -0.7665,\n        -0.2922, -1.1103,  0.2238, -1.1903, -0.7103,  0.0669, -0.4361, -3.1099,\n        -0.4318, -1.3179, -0.7406,  0.7514, -0.2831, -0.7163, -0.2272,  1.6657,\n         3.2804,  0.8348, -0.2272,  1.7842,  1.0964, -0.3966,  0.0971, -0.7673,\n         1.8971, -0.8723, -0.4088,  0.8113,  0.1556, -0.4659, -0.1816,  0.3522,\n         1.2578,  1.2654, -0.3909,  1.0688, -0.6990, -1.1283, -0.8453,  1.3101,\n         1.0594, -0.7479,  1.4743, -0.0555, -0.1019,  0.1501,  0.9965,  0.3711,\n         0.7922,  0.7400, -2.0498, -0.5238,  1.0245, -0.2177,  0.2523, -0.4410,\n         0.4364,  0.6437, -0.8116,  0.3689,  0.5467, -0.1331,  0.2083,  0.0602,\n        -1.8827,  0.4285, -0.5434,  0.6670,  0.3535,  0.0467, -1.4133,  0.7259,\n         0.3776,  1.7430, -0.7549, -0.0593, -1.1996,  0.6242, -0.4139,  1.2105,\n         0.7920,  0.4776,  1.2763, -1.1219,  1.3993,  0.9764, -0.8959,  0.2804,\n        -0.2115,  0.3348, -0.5506,  0.3897,  0.6249, -0.2774, -1.2505,  0.6664,\n        -2.9536,  1.4317, -0.3840,  0.0240, -0.5359, -0.1205,  0.8461, -0.9536,\n         1.5667, -0.6656,  0.3445, -0.2955,  1.2170, -1.8045,  0.1053,  0.1490,\n        -0.6160, -1.4852, -0.8070, -0.5910])"},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.vectors[TEXT.vocab.stoi['<pad>']]"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"wZD-aCrLwmXE","outputId":"5cc732a6-59c4-4e35-a6db-8de3c1b91e74"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"torch.Size([35807, 300])"},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.vectors.shape"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"2BS3hRnfwmXF","outputId":"8c03e4f5-e0e2-44ae-abdd-894ef710295e"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["BATCH_SIZE = 32\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    sort_key=lambda x: len(x.text),\n","    sort_within_batch=True,\n","    device=device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"gRE0KkA5wmXF"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["model = BiGRU(INPUT_DIM,\n","            EMBEDDING_DIM,\n","            HIDDEN_DIM,\n","            OUTPUT_DIM,\n","            N_LAYERS,\n","            BIDIRECTIONAL,\n","            DROPOUT,\n","            PAD_IDX)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"zuZ3SbBtwmXF"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 22,244,181 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Ww_8P1_-wmXF","outputId":"0d8efdaf-3281-415c-c5be-708198ca666b"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([35807, 300])\n"]}],"source":["pretrained_embeddings = TEXT.vocab.vectors\n","print(pretrained_embeddings.shape)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"5UnV7elFwmXG","outputId":"9bcb8b6b-6fea-4853-e5e5-5d064fdfe51a"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"tensor([[ 1.3386,  1.0568,  1.0754,  ...,  0.8396, -0.6316, -1.5424],\n        [ 0.2830, -0.0118,  2.8122,  ..., -1.4852, -0.8070, -0.5910],\n        [-0.0320,  0.2715, -0.2891,  ...,  0.1562, -0.3906, -0.1592],\n        ...,\n        [ 0.4066,  1.0539,  0.1286,  ..., -0.7367,  0.0761, -1.6207],\n        [ 0.7743,  2.2916, -0.9739,  ..., -0.2869,  2.4793,  0.4265],\n        [ 1.2922,  0.4906, -1.7092,  ..., -0.8636, -0.6713,  1.0700]])"},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["model.embedding.weight.data.copy_(pretrained_embeddings)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"3EXchQ56wmXG","outputId":"7b5754b9-410c-466e-bdb6-c1f16cfc1aef"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.0320,  0.2715, -0.2891,  ...,  0.1562, -0.3906, -0.1592],\n","        ...,\n","        [ 0.4066,  1.0539,  0.1286,  ..., -0.7367,  0.0761, -1.6207],\n","        [ 0.7743,  2.2916, -0.9739,  ..., -0.2869,  2.4793,  0.4265],\n","        [ 1.2922,  0.4906, -1.7092,  ..., -0.8636, -0.6713,  1.0700]])\n"]}],"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","print(model.embedding.weight.data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"AON-qIUowmXG","outputId":"cb1ceda2-14b5-40b2-cdf0-5e65182f9176"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["optimizer = optim.Adam(model.parameters(),lr=1e-3)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"j9_KDojHwmXH"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.668 | Train Acc: 60.07%\n","\t Val. Loss: 0.652 |  Val. Acc: 65.15%\n","Epoch: 02 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.610 | Train Acc: 67.96%\n","\t Val. Loss: 0.551 |  Val. Acc: 55.12%\n","Epoch: 03 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.530 | Train Acc: 74.26%\n","\t Val. Loss: 0.507 |  Val. Acc: 50.70%\n","Epoch: 04 | Epoch Time: 1m 18s\n","\tTrain Loss: 0.487 | Train Acc: 77.14%\n","\t Val. Loss: 0.492 |  Val. Acc: 49.16%\n","Epoch: 05 | Epoch Time: 1m 17s\n","\tTrain Loss: 0.463 | Train Acc: 78.15%\n","\t Val. Loss: 0.498 |  Val. Acc: 49.78%\n","Epoch: 06 | Epoch Time: 1m 17s\n","\tTrain Loss: 0.443 | Train Acc: 79.36%\n","\t Val. Loss: 0.494 |  Val. Acc: 49.36%\n","Epoch: 07 | Epoch Time: 1m 17s\n","\tTrain Loss: 0.426 | Train Acc: 80.34%\n","\t Val. Loss: 0.488 |  Val. Acc: 48.77%\n","Epoch: 08 | Epoch Time: 1m 17s\n","\tTrain Loss: 0.410 | Train Acc: 81.18%\n","\t Val. Loss: 0.489 |  Val. Acc: 48.92%\n","Epoch: 09 | Epoch Time: 1m 16s\n","\tTrain Loss: 0.398 | Train Acc: 81.84%\n","\t Val. Loss: 0.489 |  Val. Acc: 48.93%\n","Epoch: 10 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.387 | Train Acc: 82.68%\n","\t Val. Loss: 0.494 |  Val. Acc: 49.38%\n","Epoch: 11 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.376 | Train Acc: 83.01%\n","\t Val. Loss: 0.510 |  Val. Acc: 51.02%\n","Epoch: 12 | Epoch Time: 1m 16s\n","\tTrain Loss: 0.369 | Train Acc: 83.40%\n","\t Val. Loss: 0.504 |  Val. Acc: 50.41%\n","Epoch: 13 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.362 | Train Acc: 83.88%\n","\t Val. Loss: 0.529 |  Val. Acc: 52.87%\n","Epoch: 14 | Epoch Time: 1m 16s\n","\tTrain Loss: 0.358 | Train Acc: 84.26%\n","\t Val. Loss: 0.501 |  Val. Acc: 50.09%\n","Epoch: 15 | Epoch Time: 1m 18s\n","\tTrain Loss: 0.351 | Train Acc: 84.42%\n","\t Val. Loss: 0.505 |  Val. Acc: 50.48%\n","Epoch: 16 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.345 | Train Acc: 84.67%\n","\t Val. Loss: 0.564 |  Val. Acc: 56.37%\n","Epoch: 17 | Epoch Time: 1m 16s\n","\tTrain Loss: 0.342 | Train Acc: 84.77%\n","\t Val. Loss: 0.527 |  Val. Acc: 52.72%\n","Epoch: 18 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.338 | Train Acc: 85.00%\n","\t Val. Loss: 0.525 |  Val. Acc: 52.53%\n","Epoch: 19 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.337 | Train Acc: 85.01%\n","\t Val. Loss: 0.560 |  Val. Acc: 55.96%\n","Epoch: 20 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.335 | Train Acc: 85.32%\n","\t Val. Loss: 0.531 |  Val. Acc: 53.13%\n"]}],"source":["N_EPOCHS = 20\n","\n","INCLUDE_LENGTHS=True\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion,INCLUDE_LENGTHS)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, INCLUDE_LENGTHS)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), './Reddit Data/model/w2vec_BiGRUmodel.pt')\n","    #else:\n","        #break\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_loss*100:.2f}%')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"YBriStcrwmXH","outputId":"c191caf1-3e64-4917-b37b-3089dfcc7b58"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7576497395833334, 'precision': 0.7958366693354684, 'recall': 0.6700370744860128, 'f1': 0.7275388838060384, 'matthews_corr': 0.5183392215429762}\n"]}],"source":["y_pred,y_pred_prob,y_true = predict(model,test_iterator,INCLUDE_LENGTHS)\n","metrics=get_evaluation_metrics(y_true,y_pred)\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"db94T4pfwmXH","outputId":"6e71fce9-2c22-480c-c064-a28d7940b9ae"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7679036458333334, 'precision': 0.7926319787314849, 'recall': 0.7034041118975396, 'f1': 0.7453571428571428, 'matthews_corr': 0.5367420831252269}\n"]}],"source":["model.load_state_dict(torch.load('./Reddit Data/model/w2vec_BiGRUmodel.pt'))\n","y_pred,y_pred_prob,y_true = predict(model,test_iterator,INCLUDE_LENGTHS)\n","\n","metrics=get_evaluation_metrics(y_true,y_pred)\n","evaluation_dict['word2vec+BiGRU']=[metrics,y_pred,y_pred_prob,y_true]\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"SyAKro_vwmXH","outputId":"ae039309-68c7-4ca0-ac10-a1159a12f695"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"{'word2vec+BiLSTM': [{'accuracy': 0.765869140625,\n   'precision': 0.7913093196112064,\n   'recall': 0.6996966632962589,\n   'f1': 0.7426884894016635,\n   'matthews_corr': 0.5327646215251076},\n  array([1., 0., 0., ..., 0., 0., 0.]),\n  array([0., 0., 0., ..., 0., 0., 0.])],\n 'word2vec+BiGRU': [{'accuracy': 0.7639973958333334,\n   'precision': 0.7643778319972115,\n   'recall': 0.7391304347826086,\n   'f1': 0.751542152159013,\n   'matthews_corr': 0.5271958407746923},\n  array([1., 0., 0., ..., 0., 0., 0.]),\n  array([0., 0., 0., ..., 0., 0., 0.])]}"},"execution_count":167,"metadata":{},"output_type":"execute_result"}],"source":["evaluation_dict"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"ly1NqJwFwmXI","outputId":"7eb9ae1b-4b8f-4e0e-f4da-5d58a4567e35"}},{"cell_type":"markdown","source":["**CNN**"],"metadata":{"collapsed":false,"id":"ga8inQvTwmXI"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["TEXT = data.Field(sequential=True, batch_first=True)\n","LABEL = data.LabelField(dtype=torch.float, use_vocab=False, preprocessing=int)\n","\n","fields = {'Label_encode': ('label', LABEL), 'Tokens': ('text', TEXT)}"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"-pDcJAA7wmXI"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["current_p = os.getcwd()\n","file_p = os.path.join(current_p, 'Reddit Data')\n","train_data, valid_data, test_data = data.TabularDataset.splits(\n","    path=file_p,\n","    train='train_lstem3.json',\n","    validation='valid_lstem3.json',\n","    test='test_lstem3.json',\n","    format='json',\n","    fields=fields\n",")\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"_xp1Ox0qwmXI"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["w2v_embeddings = vocab.Vectors(name = 'Reddit Data/Word2Vec/GoogleNews_w2vec.txt',\n","                               cache = 'Reddit Data/Word2Vec',\n","                               unk_init = torch.Tensor.normal_)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"7AhwN7qEwmXI"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["TEXT.build_vocab(train_data, vectors=w2v_embeddings)\n","LABEL.build_vocab(train_data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"RT9OvWY1wmXJ"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"torch.Size([48637, 300])"},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.vectors.shape"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"nD6XEcXcwmXJ","outputId":"e3a05166-9dfb-4b12-a951-a8a3b5d7c4ed"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["BATCH_SIZE = 32\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    sort_key=lambda x: len(x.text),\n","    sort_within_batch=True,\n","    device=device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"leq0khnzwmXJ"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 300\n","N_FILTERS = 100\n","FILTER_SIZES = [2,3]\n","OUTPUT_DIM = 1\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = CNN1d(INPUT_DIM,\n","              EMBEDDING_DIM,\n","              N_FILTERS,\n","              FILTER_SIZES,\n","              OUTPUT_DIM,\n","              DROPOUT,\n","              PAD_IDX)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"MsE5g1TDwmXJ"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 14,741,501 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"HxeWc2pewmXK","outputId":"28f3ec75-7cdb-47bc-a029-6e1cb8f6942a"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"tensor([[ 0.3842, -0.1838, -0.6351,  ...,  0.4819,  1.3383, -0.0965],\n        [-0.2722,  1.0216, -0.9359,  ..., -0.0260,  0.6247, -0.3309],\n        [-0.5881,  0.9026,  1.0273,  ..., -0.4808, -1.5580,  1.7417],\n        ...,\n        [-1.1197,  0.2241, -0.2745,  ..., -0.6440,  0.8730, -0.9475],\n        [ 0.7263,  0.8048, -1.1821,  ..., -2.0554,  0.5140,  1.0250],\n        [-0.4894, -0.5980, -0.4186,  ...,  1.1885,  0.4575,  0.0318]])"},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["pretrained_embeddings = TEXT.vocab.vectors\n","\n","model.embedding.weight.data.copy_(pretrained_embeddings)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"QgoBEbIYwmXK","outputId":"612d380e-76dd-479d-9467-ff113dd6093e"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"-UmT5o_OwmXK"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.5881,  0.9026,  1.0273,  ..., -0.4808, -1.5580,  1.7417],\n","        ...,\n","        [-1.1197,  0.2241, -0.2745,  ..., -0.6440,  0.8730, -0.9475],\n","        [ 0.7263,  0.8048, -1.1821,  ..., -2.0554,  0.5140,  1.0250],\n","        [-0.4894, -0.5980, -0.4186,  ...,  1.1885,  0.4575,  0.0318]])\n"]}],"source":["print(model.embedding.weight.data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"qv5xZa06wmXK","outputId":"52581968-08b9-4d66-ecdf-8832d0d8c652"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["optimizer = optim.Adam(model.parameters(),lr=1e-3)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"u5S7IJKrwmXL"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 17s\n","\tTrain Loss: 0.561 | Train Acc: 70.30%\n","\t Val. Loss: 0.511 |  Val. Acc: 51.09%\n","Epoch: 02 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.479 | Train Acc: 76.79%\n","\t Val. Loss: 0.546 |  Val. Acc: 54.60%\n","Epoch: 03 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.425 | Train Acc: 80.37%\n","\t Val. Loss: 0.525 |  Val. Acc: 52.52%\n","Epoch: 04 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.378 | Train Acc: 83.16%\n","\t Val. Loss: 0.516 |  Val. Acc: 51.59%\n","Epoch: 05 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.333 | Train Acc: 85.44%\n","\t Val. Loss: 0.555 |  Val. Acc: 55.47%\n","Epoch: 06 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.294 | Train Acc: 87.35%\n","\t Val. Loss: 0.609 |  Val. Acc: 60.85%\n","Epoch: 07 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.259 | Train Acc: 89.01%\n","\t Val. Loss: 0.677 |  Val. Acc: 67.68%\n","Epoch: 08 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.229 | Train Acc: 90.45%\n","\t Val. Loss: 0.717 |  Val. Acc: 71.65%\n","Epoch: 09 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.205 | Train Acc: 91.48%\n","\t Val. Loss: 0.800 |  Val. Acc: 79.98%\n","Epoch: 10 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.181 | Train Acc: 92.59%\n","\t Val. Loss: 0.890 |  Val. Acc: 88.96%\n","Epoch: 11 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.166 | Train Acc: 93.24%\n","\t Val. Loss: 0.987 |  Val. Acc: 98.74%\n","Epoch: 12 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.151 | Train Acc: 93.84%\n","\t Val. Loss: 1.070 |  Val. Acc: 106.98%\n","Epoch: 13 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.140 | Train Acc: 94.40%\n","\t Val. Loss: 1.154 |  Val. Acc: 115.45%\n","Epoch: 14 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.130 | Train Acc: 94.77%\n","\t Val. Loss: 1.280 |  Val. Acc: 127.97%\n","Epoch: 15 | Epoch Time: 0m 17s\n","\tTrain Loss: 0.120 | Train Acc: 95.19%\n","\t Val. Loss: 1.394 |  Val. Acc: 139.43%\n","Epoch: 16 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.114 | Train Acc: 95.50%\n","\t Val. Loss: 1.456 |  Val. Acc: 145.62%\n","Epoch: 17 | Epoch Time: 0m 17s\n","\tTrain Loss: 0.109 | Train Acc: 95.71%\n","\t Val. Loss: 1.533 |  Val. Acc: 153.30%\n","Epoch: 18 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.104 | Train Acc: 95.93%\n","\t Val. Loss: 1.619 |  Val. Acc: 161.88%\n","Epoch: 19 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.099 | Train Acc: 96.21%\n","\t Val. Loss: 1.705 |  Val. Acc: 170.55%\n","Epoch: 20 | Epoch Time: 0m 16s\n","\tTrain Loss: 0.094 | Train Acc: 96.39%\n","\t Val. Loss: 1.761 |  Val. Acc: 176.07%\n"]}],"source":["N_EPOCHS = 20\n","\n","INCLUDE_LENGTHS=False\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion,INCLUDE_LENGTHS)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, INCLUDE_LENGTHS)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), './Reddit Data/model/w2vec_CNNmodel.pt')\n","    #else:\n","        #break\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_loss*100:.2f}%')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"VUFZ3S3xwmXL","outputId":"d9ffee3a-a13c-4324-ad7f-5c587e21f0db"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7331307534185361, 'precision': 0.744378698224852, 'recall': 0.6907027818448024, 'f1': 0.7165369280425288, 'matthews_corr': 0.466254507491087}\n"]}],"source":["y_pred,y_pred_prob,y_true = predict(model,test_iterator,INCLUDE_LENGTHS)\n","\n","metrics=get_evaluation_metrics(y_true,y_pred)\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"IV-ra1U3wmXL","outputId":"74b26be0-d28a-4318-e208-1ca93487f249"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7484136205201537, 'precision': 0.7769182521430065, 'recall': 0.6800878477306003, 'f1': 0.7252854493998243, 'matthews_corr': 0.4988539116119869}\n"]}],"source":["model.load_state_dict(torch.load('./Reddit Data/model/w2vec_CNNmodel.pt'))\n","y_pred,y_pred_prob,y_true = predict(model,test_iterator,INCLUDE_LENGTHS)\n","\n","metrics=get_evaluation_metrics(y_true,y_pred)\n","evaluation_dict['word2vec+CNN']=[metrics,y_pred,y_pred_prob,y_true]\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"c8shbY5bwmXM","outputId":"ce3e5919-dca9-456a-f818-03579bc3a3a8"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"{'word2vec+BiLSTM': [{'accuracy': 0.765869140625,\n   'precision': 0.7913093196112064,\n   'recall': 0.6996966632962589,\n   'f1': 0.7426884894016635,\n   'matthews_corr': 0.5327646215251076},\n  array([1., 0., 0., ..., 0., 0., 0.]),\n  array([0., 0., 0., ..., 0., 0., 0.])],\n 'word2vec+BiGRU': [{'accuracy': 0.7639973958333334,\n   'precision': 0.7643778319972115,\n   'recall': 0.7391304347826086,\n   'f1': 0.751542152159013,\n   'matthews_corr': 0.5271958407746923},\n  array([1., 0., 0., ..., 0., 0., 0.]),\n  array([0., 0., 0., ..., 0., 0., 0.])],\n 'word2vec+CNN': [{'accuracy': 0.7527035481276253,\n   'precision': 0.7335873895721462,\n   'recall': 0.7750732064421669,\n   'f1': 0.7537599003292694,\n   'matthews_corr': 0.506547021492231},\n  array([1., 0., 0., ..., 1., 1., 1.]),\n  array([1., 0., 0., ..., 0., 1., 1.])]}"},"execution_count":181,"metadata":{},"output_type":"execute_result"}],"source":["evaluation_dict"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"VXaRg7vnwmXM","outputId":"1ae117d7-8bca-4b49-f7f9-835110f44101"}},{"cell_type":"markdown","source":["**GLOVE + DL**"],"metadata":{"collapsed":false,"id":"f2GaZaOEwmXM"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["glove_vec = vocab.Vectors(name='Reddit Data/glove/glove.twitter.27B.100d.txt',\n","                          cache='Reddit Data/glove',\n","                          unk_init=torch.Tensor.normal_)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"gCtBsK6ZwmXM"}},{"cell_type":"markdown","source":["BiLSTM & BiGRU"],"metadata":{"collapsed":false,"id":"zT80xoKRwmXM"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["TEXT = data.Field(sequential=True, include_lengths=True)\n","LABEL = data.LabelField(dtype=torch.float, use_vocab=False, preprocessing=int)\n","\n","fields = {'Label_encode': ('label', LABEL), 'Tokens': ('text', TEXT)}\n","\n","file_p = os.path.join(current_p, 'Reddit Data')\n","train_data, valid_data, test_data = data.TabularDataset.splits(\n","    path=file_p,\n","    train='train.json',\n","    validation='valid.json',\n","    test='test.json',\n","    format='json',\n","    fields=fields\n",")"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"19V_7HPgwmXN"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["TEXT.build_vocab(train_data,vectors=glove_vec)\n","LABEL.build_vocab(train_data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"2cLXWjogwmXN"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"torch.Size([35807, 100])"},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.vectors.shape"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"DgMjacoYwmXN","outputId":"5ba1d017-1e55-4989-abd9-4929fee5365d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["BATCH_SIZE = 32\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    sort_key=lambda x: len(x.text),\n","    sort_within_batch=True,\n","    device=device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Yc2r3TqHwmXN"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["#BiLSTM\n","INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 64\n","OUTPUT_DIM = 1\n","N_LAYERS = 10\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = BiLSTM(INPUT_DIM,\n","               EMBEDDING_DIM,\n","               HIDDEN_DIM,\n","               OUTPUT_DIM,\n","               N_LAYERS,\n","               BIDIRECTIONAL,\n","               DROPOUT,\n","               PAD_IDX)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"P4ZRYn8KwmXO"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 4,559,773 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Pjxe_OkFwmXO","outputId":"3637b866-d1c8-4f83-ee83-3f5a529cdea0"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([35807, 100])\n"]}],"source":["pretrained_embeddings = TEXT.vocab.vectors\n","print(pretrained_embeddings.shape)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"lRS8NRSewmXO","outputId":"5a8b7bcd-e93c-44b2-8373-921abcb58a43"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"tensor([[-0.6374, -0.0418, -1.4557,  ..., -0.0390,  0.1676,  2.6425],\n        [-1.1838, -1.2965,  0.8211,  ..., -0.0688, -1.5944, -1.1358],\n        [ 0.4274, -0.0909, -0.1783,  ...,  0.7011, -0.1588, -0.1800],\n        ...,\n        [-0.3403, -1.4027,  0.8282,  ..., -0.7417, -1.0885,  0.4222],\n        [ 1.2101, -0.0990,  0.3096,  ...,  0.5585, -0.8345, -0.7272],\n        [ 0.7422, -0.9827, -0.8505,  ...,  1.2911, -0.5511,  0.6086]])"},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["model.embedding.weight.data.copy_(pretrained_embeddings)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"ccMoz6w3wmXP","outputId":"701f6d43-5304-4a3f-9f3f-9a684da061e9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"twG5j0JLwmXP"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.4274, -0.0909, -0.1783,  ...,  0.7011, -0.1588, -0.1800],\n","        ...,\n","        [-0.3403, -1.4027,  0.8282,  ..., -0.7417, -1.0885,  0.4222],\n","        [ 1.2101, -0.0990,  0.3096,  ...,  0.5585, -0.8345, -0.7272],\n","        [ 0.7422, -0.9827, -0.8505,  ...,  1.2911, -0.5511,  0.6086]])\n"]}],"source":["print(model.embedding.weight.data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"QUPx9chlwmXP","outputId":"664e161e-a850-49a1-938e-35d45cf79d9d"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 4,559,773 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"fYAKTkv5wmXP","outputId":"af787532-1961-4864-d6cd-e4e8faa6d6f9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"V6s8vHTKwmXP"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.606 | Train Acc: 66.97%\n","\t Val. Loss: 0.520 |  Val. Acc: 52.04%\n","Epoch: 02 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.518 | Train Acc: 74.60%\n","\t Val. Loss: 0.502 |  Val. Acc: 50.24%\n","Epoch: 03 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.489 | Train Acc: 76.46%\n","\t Val. Loss: 0.493 |  Val. Acc: 49.35%\n","Epoch: 04 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.469 | Train Acc: 77.69%\n","\t Val. Loss: 0.487 |  Val. Acc: 48.74%\n","Epoch: 05 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.456 | Train Acc: 78.58%\n","\t Val. Loss: 0.494 |  Val. Acc: 49.40%\n","Epoch: 06 | Epoch Time: 1m 0s\n","\tTrain Loss: 0.443 | Train Acc: 79.45%\n","\t Val. Loss: 0.492 |  Val. Acc: 49.21%\n","Epoch: 07 | Epoch Time: 1m 0s\n","\tTrain Loss: 0.433 | Train Acc: 79.78%\n","\t Val. Loss: 0.485 |  Val. Acc: 48.54%\n","Epoch: 08 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.420 | Train Acc: 80.56%\n","\t Val. Loss: 0.494 |  Val. Acc: 49.36%\n","Epoch: 09 | Epoch Time: 1m 0s\n","\tTrain Loss: 0.413 | Train Acc: 80.93%\n","\t Val. Loss: 0.520 |  Val. Acc: 52.01%\n","Epoch: 10 | Epoch Time: 1m 0s\n","\tTrain Loss: 0.402 | Train Acc: 81.55%\n","\t Val. Loss: 0.488 |  Val. Acc: 48.75%\n","Epoch: 11 | Epoch Time: 1m 0s\n","\tTrain Loss: 0.395 | Train Acc: 81.91%\n","\t Val. Loss: 0.496 |  Val. Acc: 49.60%\n","Epoch: 12 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.387 | Train Acc: 82.33%\n","\t Val. Loss: 0.514 |  Val. Acc: 51.38%\n","Epoch: 13 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.381 | Train Acc: 82.72%\n","\t Val. Loss: 0.498 |  Val. Acc: 49.84%\n","Epoch: 14 | Epoch Time: 1m 0s\n","\tTrain Loss: 0.372 | Train Acc: 83.13%\n","\t Val. Loss: 0.510 |  Val. Acc: 50.99%\n","Epoch: 15 | Epoch Time: 1m 2s\n","\tTrain Loss: 0.365 | Train Acc: 83.62%\n","\t Val. Loss: 0.523 |  Val. Acc: 52.28%\n","Epoch: 16 | Epoch Time: 1m 1s\n","\tTrain Loss: 0.361 | Train Acc: 83.81%\n","\t Val. Loss: 0.526 |  Val. Acc: 52.63%\n","Epoch: 17 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.356 | Train Acc: 83.99%\n","\t Val. Loss: 0.513 |  Val. Acc: 51.31%\n","Epoch: 18 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.347 | Train Acc: 84.49%\n","\t Val. Loss: 0.531 |  Val. Acc: 53.12%\n","Epoch: 19 | Epoch Time: 1m 0s\n","\tTrain Loss: 0.343 | Train Acc: 84.76%\n","\t Val. Loss: 0.544 |  Val. Acc: 54.39%\n","Epoch: 20 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.337 | Train Acc: 84.88%\n","\t Val. Loss: 0.532 |  Val. Acc: 53.19%\n"]}],"source":["N_EPOCHS = 20\n","\n","INCLUDE_LENGTHS = True\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, INCLUDE_LENGTHS)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, INCLUDE_LENGTHS)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), './Reddit Data/model/glove_BiLSTMmodel.pt')\n","    #else:\n","        #break\n","    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_loss * 100:.2f}%')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Y9pQQGuVwmXQ","outputId":"fdfc2c86-b188-4c37-e40e-45f52e54358e"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"{'accuracy': 0.767333984375,\n 'precision': 0.7918011007781363,\n 'recall': 0.703067071115605,\n 'f1': 0.7448004998661072,\n 'matthews_corr': 0.5355690618220835}"},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["\n","y_pred, y_pred_prob, y_true = predict(model, test_iterator, INCLUDE_LENGTHS)\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","metrics"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"YK5EErqMwmXQ","outputId":"a7ad1111-9a33-43b1-eee0-e259df7599f2"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7705078125, 'precision': 0.8068584942845881, 'recall': 0.689922480620155, 'f1': 0.7438226744186047, 'matthews_corr': 0.5436842412532721}\n"]}],"source":["model.load_state_dict(torch.load('./Reddit Data/model/glove_BiLSTMmodel.pt'))\n","\n","y_pred, y_pred_prob, y_true = predict(model, test_iterator, INCLUDE_LENGTHS)\n","\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","evaluation_dict['glove+BiLSTM'] = [metrics, y_pred, y_pred_prob,y_true]\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"6uyV509PwmXQ","outputId":"6fcc4edb-ad2d-4d5e-b45d-c0def6f6064d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["glove_vec = vocab.Vectors(name='Reddit Data/glove/glove.twitter.27B.100d.txt',\n","                          cache='Reddit Data/glove',\n","                          unk_init=torch.Tensor.normal_)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"CN08AzQswmXR"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["\n","TEXT = data.Field(sequential=True, include_lengths=True)\n","LABEL = data.LabelField(dtype=torch.float, use_vocab=False, preprocessing=int)\n","\n","fields = {'Label_encode': ('label', LABEL), 'Tokens': ('text', TEXT)}\n","\n","file_p = os.path.join(current_p, 'Reddit Data')\n","train_data, valid_data, test_data = data.TabularDataset.splits(\n","    path=file_p,\n","    train='train.json',\n","    validation='valid.json',\n","    test='test.json',\n","    format='json',\n","    fields=fields\n",")\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"MBGXA2jnwmXR"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"torch.Size([35807, 100])"},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.build_vocab(train_data, vectors=glove_vec)\n","LABEL.build_vocab(train_data)\n","TEXT.vocab.vectors.shape"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"k2ODPPUzwmXR","outputId":"8dffbef2-d5e4-4fe3-e8d7-c55cafcb2954"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["BATCH_SIZE = 32\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    sort_key=lambda x: len(x.text),\n","    sort_within_batch=True,\n","    device=device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"rktP8WpJwmXR"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["#BiGRU\n","INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 64\n","OUTPUT_DIM = 1\n","N_LAYERS = 10\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = BiGRU(INPUT_DIM,\n","            EMBEDDING_DIM,\n","            HIDDEN_DIM,\n","            OUTPUT_DIM,\n","            N_LAYERS,\n","            BIDIRECTIONAL,\n","            DROPOUT,\n","            PAD_IDX)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"ookp1klIwmXR"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 4,315,037 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"IvyJ2PhLwmXS","outputId":"3842c96c-ba03-42f0-eb7b-a8bd6c464c62"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([35807, 100])\n"]}],"source":["pretrained_embeddings = TEXT.vocab.vectors\n","print(pretrained_embeddings.shape)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"u0av6g9pwmXS","outputId":"9ce58eb9-3b7a-40bf-8730-4e496ba5a8bd"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"tensor([[-2.0381,  0.7155, -0.4842,  ...,  0.0315, -0.9411,  0.0561],\n        [-0.9160, -1.4147,  2.4218,  ..., -0.8534, -1.8712, -0.2209],\n        [ 0.4274, -0.0909, -0.1783,  ...,  0.7011, -0.1588, -0.1800],\n        ...,\n        [ 0.4630, -0.7078, -1.4032,  ..., -0.1069, -1.0257,  0.1335],\n        [-0.7088,  0.2905, -0.4676,  ...,  0.5253,  0.4376,  0.9916],\n        [-1.9795,  0.3914, -1.9789,  ..., -1.0945, -0.8275, -0.2732]])"},"execution_count":104,"metadata":{},"output_type":"execute_result"}],"source":["model.embedding.weight.data.copy_(pretrained_embeddings)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"p3SfFUPFwmXS","outputId":"e92c39f1-737f-4cb1-b40f-83118a6aac1a"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"nqUOPZMOwmXS"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.4274, -0.0909, -0.1783,  ...,  0.7011, -0.1588, -0.1800],\n","        ...,\n","        [ 0.4630, -0.7078, -1.4032,  ..., -0.1069, -1.0257,  0.1335],\n","        [-0.7088,  0.2905, -0.4676,  ...,  0.5253,  0.4376,  0.9916],\n","        [-1.9795,  0.3914, -1.9789,  ..., -1.0945, -0.8275, -0.2732]])\n"]}],"source":["print(model.embedding.weight.data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"zupcjwiwwmXT","outputId":"485cb935-e06b-49a8-85b1-c77f827dd69b"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 4,315,037 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"DGblSNcMwmXT","outputId":"f5d11ce7-7261-4333-f604-fe36a320db85"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"aQALAWqwwmXT"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.578 | Train Acc: 69.56%\n","\t Val. Loss: 0.537 |  Val. Acc: 53.74%\n","Epoch: 02 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.510 | Train Acc: 75.08%\n","\t Val. Loss: 0.489 |  Val. Acc: 48.86%\n","Epoch: 03 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.487 | Train Acc: 76.48%\n","\t Val. Loss: 0.487 |  Val. Acc: 48.68%\n","Epoch: 04 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.466 | Train Acc: 77.87%\n","\t Val. Loss: 0.485 |  Val. Acc: 48.47%\n","Epoch: 05 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.454 | Train Acc: 78.64%\n","\t Val. Loss: 0.490 |  Val. Acc: 49.00%\n","Epoch: 06 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.442 | Train Acc: 79.21%\n","\t Val. Loss: 0.489 |  Val. Acc: 48.94%\n","Epoch: 07 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.432 | Train Acc: 79.91%\n","\t Val. Loss: 0.483 |  Val. Acc: 48.33%\n","Epoch: 08 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.423 | Train Acc: 80.36%\n","\t Val. Loss: 0.483 |  Val. Acc: 48.33%\n","Epoch: 09 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.415 | Train Acc: 80.88%\n","\t Val. Loss: 0.493 |  Val. Acc: 49.32%\n","Epoch: 10 | Epoch Time: 0m 57s\n","\tTrain Loss: 0.406 | Train Acc: 81.38%\n","\t Val. Loss: 0.485 |  Val. Acc: 48.54%\n","Epoch: 11 | Epoch Time: 0m 57s\n","\tTrain Loss: 0.399 | Train Acc: 81.69%\n","\t Val. Loss: 0.501 |  Val. Acc: 50.13%\n","Epoch: 12 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.392 | Train Acc: 82.14%\n","\t Val. Loss: 0.497 |  Val. Acc: 49.68%\n","Epoch: 13 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.384 | Train Acc: 82.49%\n","\t Val. Loss: 0.530 |  Val. Acc: 52.99%\n","Epoch: 14 | Epoch Time: 0m 57s\n","\tTrain Loss: 0.379 | Train Acc: 82.73%\n","\t Val. Loss: 0.498 |  Val. Acc: 49.78%\n","Epoch: 15 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.373 | Train Acc: 83.16%\n","\t Val. Loss: 0.507 |  Val. Acc: 50.74%\n","Epoch: 16 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.369 | Train Acc: 83.36%\n","\t Val. Loss: 0.519 |  Val. Acc: 51.90%\n","Epoch: 17 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.363 | Train Acc: 83.64%\n","\t Val. Loss: 0.506 |  Val. Acc: 50.59%\n","Epoch: 18 | Epoch Time: 0m 59s\n","\tTrain Loss: 0.360 | Train Acc: 83.75%\n","\t Val. Loss: 0.505 |  Val. Acc: 50.48%\n","Epoch: 19 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.354 | Train Acc: 83.99%\n","\t Val. Loss: 0.534 |  Val. Acc: 53.44%\n","Epoch: 20 | Epoch Time: 0m 58s\n","\tTrain Loss: 0.350 | Train Acc: 84.34%\n","\t Val. Loss: 0.514 |  Val. Acc: 51.40%\n"]}],"source":["N_EPOCHS = 20\n","\n","INCLUDE_LENGTHS = True\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, INCLUDE_LENGTHS)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, INCLUDE_LENGTHS)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), './Reddit Data/model/glove_BiGRUmodel.pt')\n","    #else:\n","        #break\n","    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_loss * 100:.2f}%')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"VulSym2swmXT","outputId":"3dcb5880-5b34-4509-c874-5e4f86ff558b"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7701009114583334, 'precision': 0.7964905588403586, 'recall': 0.7037411526794742, 'f1': 0.7472488145298382, 'matthews_corr': 0.5413550219615594}\n"]}],"source":["y_pred, y_pred_prob, y_true = predict(model, test_iterator, INCLUDE_LENGTHS)\n","\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"rSiFP3DQwmXT","outputId":"9a9610ff-032b-4755-a959-dcd4ffb272d2"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7696940104166666, 'precision': 0.7714235746764603, 'recall': 0.7433434445567914, 'f1': 0.7571232406453828, 'matthews_corr': 0.5386283816006766}\n"]}],"source":["model.load_state_dict(torch.load('./Reddit Data/model/glove_BiGRUmodel.pt'))\n","\n","y_pred, y_pred_prob, y_true = predict(model, test_iterator, INCLUDE_LENGTHS)\n","\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","evaluation_dict['glove+BiGRU'] = [metrics, y_pred, y_pred_prob,y_true]\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"C6CQohv6wmXU","outputId":"c4a0bf14-77b4-48de-bee6-605be72e9283"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["#CNN\n","TEXT = data.Field(sequential=True, batch_first=True)\n","LABEL = data.LabelField(dtype=torch.float, use_vocab=False, preprocessing=int)\n","\n","fields = {'Label_encode': ('label', LABEL), 'Tokens': ('text', TEXT)}\n","\n","file_p = os.path.join(current_p, 'Reddit Data')\n","train_data, valid_data, test_data = data.TabularDataset.splits(\n","    path=file_p,\n","    train='train_lstem3.json',\n","    validation='valid_lstem3.json',\n","    test='test_lstem3.json',\n","    format='json',\n","    fields=fields\n",")"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"sIsVT8IlwmXU"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["glove_vec = vocab.Vectors(name='Reddit Data/glove/glove.twitter.27B.100d.txt',\n","                          cache='Reddit Data/glove',\n","                          unk_init=torch.Tensor.normal_)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"JFd8PK23wmXU"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["TEXT.build_vocab(train_data, vectors=glove_vec)\n","LABEL.build_vocab(train_data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"QydMHEhmwmXU"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"torch.Size([48637, 100])"},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.vectors.shape"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"fjd4LdoqwmXU","outputId":"f6244315-4b5c-43f1-fcba-a4bda5391cdb"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["BATCH_SIZE = 32\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    sort_key=lambda x: len(x.text),\n","    sort_within_batch=True,\n","    device=device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"GzislnTvwmXU"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","N_FILTERS = 64\n","FILTER_SIZES = [2, 3]\n","OUTPUT_DIM = 1\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = CNN1d(INPUT_DIM,\n","              EMBEDDING_DIM,\n","              N_FILTERS,\n","              FILTER_SIZES,\n","              OUTPUT_DIM,\n","              DROPOUT,\n","              PAD_IDX)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"M4PyI9djwmXU"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 4,895,957 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"9nicGDmUwmXV","outputId":"67d1bde7-dfd4-4be0-de8c-595e02edcb2d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["pretrained_embeddings = TEXT.vocab.vectors"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"HFEhz-TRwmXV"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"tensor([[-1.4290, -1.5285,  1.1035,  ..., -0.2543, -0.7078, -0.9456],\n        [ 0.2207,  1.8187, -1.2881,  ..., -0.7617, -1.3683, -0.4202],\n        [ 0.0310,  1.1567, -2.3635,  ...,  1.2009,  1.1024,  0.7224],\n        ...,\n        [-0.7321, -1.0117, -1.2753,  ..., -1.9088,  1.2597,  1.5051],\n        [ 0.9803,  2.0135,  0.0842,  ...,  0.6145, -0.7652,  0.6233],\n        [-0.7638,  0.5280, -0.6244,  ...,  2.4367,  0.4135, -0.7559]])"},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["model.embedding.weight.data.copy_(pretrained_embeddings)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"e-eC2IHlwmXV","outputId":"31fc08a6-2fbc-4aae-ea88-a078463a17fd"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0310,  1.1567, -2.3635,  ...,  1.2009,  1.1024,  0.7224],\n","        ...,\n","        [-0.7321, -1.0117, -1.2753,  ..., -1.9088,  1.2597,  1.5051],\n","        [ 0.9803,  2.0135,  0.0842,  ...,  0.6145, -0.7652,  0.6233],\n","        [-0.7638,  0.5280, -0.6244,  ...,  2.4367,  0.4135, -0.7559]])\n"]}],"source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","print(model.embedding.weight.data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"l1XcDzv6wmXV","outputId":"708f1f44-927c-47aa-c61b-bd5f98ae42f0"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"f_QySGLcwmXV"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.582 | Train Acc: 67.82%\n","\t Val. Loss: 0.529 |  Val. Acc: 52.91%\n","Epoch: 02 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.503 | Train Acc: 74.98%\n","\t Val. Loss: 0.518 |  Val. Acc: 51.77%\n","Epoch: 03 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.456 | Train Acc: 78.37%\n","\t Val. Loss: 0.495 |  Val. Acc: 49.52%\n","Epoch: 04 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.418 | Train Acc: 80.81%\n","\t Val. Loss: 0.504 |  Val. Acc: 50.42%\n","Epoch: 05 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.386 | Train Acc: 82.61%\n","\t Val. Loss: 0.522 |  Val. Acc: 52.18%\n","Epoch: 06 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.354 | Train Acc: 84.33%\n","\t Val. Loss: 0.531 |  Val. Acc: 53.09%\n","Epoch: 07 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.329 | Train Acc: 85.65%\n","\t Val. Loss: 0.565 |  Val. Acc: 56.54%\n","Epoch: 08 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.303 | Train Acc: 86.95%\n","\t Val. Loss: 0.567 |  Val. Acc: 56.71%\n","Epoch: 09 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.280 | Train Acc: 87.96%\n","\t Val. Loss: 0.611 |  Val. Acc: 61.07%\n","Epoch: 10 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.261 | Train Acc: 88.91%\n","\t Val. Loss: 0.657 |  Val. Acc: 65.72%\n","Epoch: 11 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.243 | Train Acc: 89.64%\n","\t Val. Loss: 0.697 |  Val. Acc: 69.74%\n","Epoch: 12 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.227 | Train Acc: 90.37%\n","\t Val. Loss: 0.732 |  Val. Acc: 73.20%\n","Epoch: 13 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.213 | Train Acc: 91.14%\n","\t Val. Loss: 0.791 |  Val. Acc: 79.09%\n","Epoch: 14 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.198 | Train Acc: 91.66%\n","\t Val. Loss: 0.867 |  Val. Acc: 86.71%\n","Epoch: 15 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.187 | Train Acc: 92.12%\n","\t Val. Loss: 0.917 |  Val. Acc: 91.67%\n","Epoch: 16 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.177 | Train Acc: 92.53%\n","\t Val. Loss: 0.985 |  Val. Acc: 98.47%\n","Epoch: 17 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.167 | Train Acc: 92.96%\n","\t Val. Loss: 1.059 |  Val. Acc: 105.87%\n","Epoch: 18 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.159 | Train Acc: 93.29%\n","\t Val. Loss: 1.111 |  Val. Acc: 111.12%\n","Epoch: 19 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.150 | Train Acc: 93.75%\n","\t Val. Loss: 1.183 |  Val. Acc: 118.31%\n","Epoch: 20 | Epoch Time: 0m 10s\n","\tTrain Loss: 0.144 | Train Acc: 93.99%\n","\t Val. Loss: 1.240 |  Val. Acc: 123.96%\n"]}],"source":["N_EPOCHS = 20\n","\n","INCLUDE_LENGTHS = False\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, INCLUDE_LENGTHS)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, INCLUDE_LENGTHS)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), './Reddit Data/model/glove_CNNmodel.pt')\n","    #else:\n","        #break\n","    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_loss * 100:.2f}%')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"6B5p9yimwmXV","outputId":"5b8074b6-d999-49f3-fc1b-86b0b0d7694a"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7591384395388328, 'precision': 0.7509516041326808, 'recall': 0.7582357247437774, 'f1': 0.7545760859666697, 'matthews_corr': 0.5181444321376383}\n"]}],"source":["model.load_state_dict(torch.load('./Reddit Data/model/glove_CNNmodel.pt'))\n","y_pred, y_pred_prob, y_true = predict(model, test_iterator, INCLUDE_LENGTHS)\n","\n","\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","evaluation_dict['glove+CNN'] = [metrics, y_pred, y_pred_prob,y_true]\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"LI3UtlJQwmXV","outputId":"cb811309-5d4e-4d19-bc93-7f744e45d6f3"}},{"cell_type":"markdown","source":["**Transformer**"],"metadata":{"collapsed":false,"id":"tEnf3v2ewmXW"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from transformers import RobertaTokenizer,AutoTokenizer,BartTokenizer,RobertaModel,AutoModel,BartModel"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"_PhRgYPlwmXW"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["class TransformerGRU(nn.Module):\n","    def __init__(self,mname,hidden_dim,output_dim,n_layers,bidirectional,dropout):\n","\n","        super().__init__()\n","\n","        if mname=='roberta':\n","            self.nlp=RobertaModel.from_pretrained('roberta-base')\n","        elif mname=='finbert':\n","            self.nlp=AutoModel.from_pretrained(\"ProsusAI/finbert\")\n","        elif mname=='bart':\n","            self.nlp=BartModel.from_pretrained(\"facebook/bart-base\")\n","        else:\n","            raise ValueError\n","\n","        if mname=='bart':\n","            embedding_dim = self.nlp.config.to_dict()['d_model']\n","\n","        else:\n","            embedding_dim = self.nlp.config.to_dict()['hidden_size']\n","\n","        self.rnn = nn.GRU(embedding_dim,\n","                          hidden_dim,\n","                          num_layers=n_layers,\n","                          bidirectional=bidirectional,\n","                          batch_first=True,\n","                          dropout=0 if n_layers < 2 else dropout)\n","\n","        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, text):\n","\n","        #text = [batch size, sent len]\n","\n","        with torch.no_grad():\n","\n","            embedded = self.nlp(text)[0]\n","\n","        #embedded = [batch size, sent len, emb dim]\n","\n","        _, hidden = self.rnn(embedded)\n","\n","        #hidden = [n layers * n directions, batch size, emb dim]\n","\n","        if self.rnn.bidirectional:\n","            hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n","        else:\n","            hidden = self.dropout(hidden[-1, :, :])\n","\n","        #hidden = [batch size, hid dim]\n","\n","        output = self.out(hidden)\n","\n","        #output = [batch size, out dim]\n","\n","        return output\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"YMEfqRtiwmXW"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def tokenize_and_cut(sentence):\n","    tokens = tokenizer.tokenize(sentence)\n","    tokens = tokens[:max_input_length-2]\n","    return tokens"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"iTLyyXLWwmXW"}},{"cell_type":"markdown","source":["RoBerta"],"metadata":{"collapsed":false,"id":"8NZRz12QwmXW"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["0 2 1 3\n"]}],"source":["#RoBert\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","max_input_length = tokenizer.max_model_input_sizes['roberta-base']\n","init_token_idx = tokenizer.cls_token_id\n","eos_token_idx = tokenizer.sep_token_id\n","pad_token_idx = tokenizer.pad_token_id\n","unk_token_idx = tokenizer.unk_token_id\n","print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Z18YTQ9lwmXW","outputId":"3b612a47-f1e1-444b-dfdd-313bc55369de"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': 1, 'text': [31653, 885, 37844, 919, 46223, 428, 946, 1597, 3068, 14131, 48288, 118, 721, 3369, 705, 821, 1794, 524, 438, 295, 1638]}\n"]}],"source":["TEXT = data.Field(batch_first=True,\n","                  use_vocab=False,\n","                  tokenize=tokenize_and_cut,\n","                  preprocessing=tokenizer.convert_tokens_to_ids,\n","                  init_token=init_token_idx,\n","                  eos_token=eos_token_idx,\n","                  pad_token=pad_token_idx,\n","                  unk_token=unk_token_idx)\n","\n","LABEL = data.LabelField(dtype=torch.float, use_vocab=False, preprocessing=int)\n","fields = [(\"label\", LABEL), (\"text\", TEXT)]\n","train_data, valid_data, test_data = data.TabularDataset.splits(\n","    path=file_p, train='train.csv',\n","    validation='valid.csv',\n","    test='test.csv',\n","    format='csv', skip_header=True, fields=fields)\n","print(vars(test_data.examples[30]))\n","LABEL.build_vocab(train_data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"y-AA2_KpwmXX","outputId":"66f1f4ef-d5da-4b48-9105-7834faf5e2b7"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["BATCH_SIZE = 32\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    sort_key=lambda x: len(x.text),\n","    sort_within_batch=True,\n","    device=device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"it3kBlawwmXX"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","\n","model = TransformerGRU('roberta',\n","                       HIDDEN_DIM,\n","                       OUTPUT_DIM,\n","                       N_LAYERS,\n","                       BIDIRECTIONAL,\n","                       DROPOUT)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"-Ckpjid2wmXX","outputId":"52ac9023-3a97-403d-adff-7056b8d55a06"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 127,404,801 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"5ByqlpkLwmXX","outputId":"292824ed-b9ca-4f55-fa24-5946ba40f8e6"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 2,759,169 trainable parameters\n"]}],"source":["for name, param in model.named_parameters():\n","    if name.startswith('nlp'):\n","        param.requires_grad = False\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"l06m-mDmwmXX","outputId":"e3f9dc17-8f15-47ff-ace3-19d072cc1184"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import torch.optim as optim\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Z8oCwGFNwmXX"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.582 | Train Acc: 68.50%\n","\t Val. Loss: 0.533 |  Val. Acc: 72.53%\n","Epoch: 02 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.539 | Train Acc: 72.07%\n","\t Val. Loss: 0.522 |  Val. Acc: 73.35%\n","Epoch: 03 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.520 | Train Acc: 73.36%\n","\t Val. Loss: 0.509 |  Val. Acc: 73.90%\n","Epoch: 04 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.506 | Train Acc: 74.43%\n","\t Val. Loss: 0.503 |  Val. Acc: 74.71%\n","Epoch: 05 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.492 | Train Acc: 75.33%\n","\t Val. Loss: 0.495 |  Val. Acc: 75.24%\n","Epoch: 06 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.479 | Train Acc: 76.38%\n","\t Val. Loss: 0.496 |  Val. Acc: 75.61%\n","Epoch: 07 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.465 | Train Acc: 77.29%\n","\t Val. Loss: 0.496 |  Val. Acc: 75.63%\n","Epoch: 08 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.455 | Train Acc: 77.80%\n","\t Val. Loss: 0.496 |  Val. Acc: 75.63%\n","Epoch: 09 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.441 | Train Acc: 78.73%\n","\t Val. Loss: 0.513 |  Val. Acc: 75.73%\n","Epoch: 10 | Epoch Time: 1m 12s\n","\tTrain Loss: 0.428 | Train Acc: 79.63%\n","\t Val. Loss: 0.501 |  Val. Acc: 75.59%\n","Epoch: 11 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.417 | Train Acc: 80.29%\n","\t Val. Loss: 0.525 |  Val. Acc: 75.35%\n","Epoch: 12 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.404 | Train Acc: 80.99%\n","\t Val. Loss: 0.521 |  Val. Acc: 75.26%\n","Epoch: 13 | Epoch Time: 1m 12s\n","\tTrain Loss: 0.394 | Train Acc: 81.59%\n","\t Val. Loss: 0.543 |  Val. Acc: 74.88%\n","Epoch: 14 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.382 | Train Acc: 82.10%\n","\t Val. Loss: 0.550 |  Val. Acc: 75.32%\n","Epoch: 15 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.372 | Train Acc: 82.89%\n","\t Val. Loss: 0.552 |  Val. Acc: 75.03%\n","Epoch: 16 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.365 | Train Acc: 83.16%\n","\t Val. Loss: 0.543 |  Val. Acc: 75.40%\n","Epoch: 17 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.359 | Train Acc: 83.54%\n","\t Val. Loss: 0.545 |  Val. Acc: 75.34%\n","Epoch: 18 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.351 | Train Acc: 83.99%\n","\t Val. Loss: 0.551 |  Val. Acc: 75.53%\n","Epoch: 19 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.345 | Train Acc: 84.39%\n","\t Val. Loss: 0.577 |  Val. Acc: 75.21%\n","Epoch: 20 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.338 | Train Acc: 84.75%\n","\t Val. Loss: 0.564 |  Val. Acc: 74.85%\n"]}],"source":["N_EPOCHS = 20\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, False)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, False)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), f'./Reddit Data/model/roberta-model.pt')\n","    #else:\n","    #break #early stop\n","\n","    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"kHaPs8PXwmXY","outputId":"f6933569-a6b8-442a-ed5b-2f345ff3b0b8"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.74853515625, 'precision': 0.7547474023647438, 'recall': 0.7099764071452646, 'f1': 0.7316776658562, 'matthews_corr': 0.4963133187981664}\n"]}],"source":["y_pred, y_pred_prob, y_true = predict(model, test_iterator, False)\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"RpSOzOszwmXY","outputId":"03e6e2f6-61e2-4202-a44d-9dcc67b8a001"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7491048177083334, 'precision': 0.7730319862095384, 'recall': 0.6801482979440512, 'f1': 0.7236216943074854, 'matthews_corr': 0.4990264158760728}\n"]}],"source":["model.load_state_dict(torch.load('./Reddit Data/model/roberta-model.pt'))\n","\n","y_pred, y_pred_prob, y_true = predict(model, test_iterator, False)\n","\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","evaluation_dict['RoBERTa'] = [metrics, y_pred, y_pred_prob,y_true]\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"rg-_drPewmXY","outputId":"27b76e51-ae76-41b7-938d-4f8089e092b8"}},{"cell_type":"markdown","source":["FINBERT"],"metadata":{"collapsed":false,"id":"nvdKCBDBwmXY"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"LZVS0D0xwmXY"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["101 102 0 100\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n","init_token_idx = tokenizer.cls_token_id\n","eos_token_idx = tokenizer.sep_token_id\n","pad_token_idx = tokenizer.pad_token_id\n","unk_token_idx = tokenizer.unk_token_id\n","print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"rYRqjV-nwmXY","outputId":"e15ba5b6-7dad-4680-c4b1-b4cab7398524"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["max_input_length = 512"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"_mTfyXvVwmXZ"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': 1, 'text': [4067, 1059, 19022, 2266, 2128, 4168, 14905, 2907, 3280, 4536, 6440, 5292, 9397, 2072, 3119, 22889, 2615, 13938, 2063, 21962, 2053, 2243]}\n"]}],"source":["TEXT = data.Field(batch_first=True,\n","                  use_vocab=False,\n","                  tokenize=tokenize_and_cut,\n","                  preprocessing=tokenizer.convert_tokens_to_ids,\n","                  init_token=init_token_idx,\n","                  eos_token=eos_token_idx,\n","                  pad_token=pad_token_idx,\n","                  unk_token=unk_token_idx)\n","\n","LABEL = data.LabelField(dtype=torch.float, use_vocab=False, preprocessing=int)\n","fields = [(\"label\", LABEL), (\"text\", TEXT)]\n","train_data, valid_data, test_data = data.TabularDataset.splits(\n","    path=file_p, train='train.csv',\n","    validation='valid.csv',\n","    test='test.csv',\n","    format='csv', skip_header=True, fields=fields)\n","print(vars(test_data.examples[30]))\n","LABEL.build_vocab(train_data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"3ihk6BsjwmXZ","outputId":"30de9eb2-f09e-4913-9eaa-d97b2aa23426"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["BATCH_SIZE = 32\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    sort_key=lambda x: len(x.text),\n","    sort_within_batch=True,\n","    device=device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"dN-dXoR7wmXZ"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","model = TransformerGRU('finbert',\n","                       HIDDEN_DIM,\n","                       OUTPUT_DIM,\n","                       N_LAYERS,\n","                       BIDIRECTIONAL,\n","                       DROPOUT)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"yXTnnetwwmXZ","outputId":"406ca05f-fd6b-429a-b95b-b4beddb32423"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 112,241,409 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"KeVPMxAqwmXZ","outputId":"79082c10-3c2f-44d3-9368-e1065bc68a58"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 2,759,169 trainable parameters\n"]}],"source":["for name, param in model.named_parameters():\n","    if name.startswith('nlp'):\n","        param.requires_grad = False\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"-mhArsPSwmXZ","outputId":"0f600bee-2e59-4bf6-8e5c-d5eab5dccdaf"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"GB8sq5VYwmXa"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.594 | Train Acc: 67.48%\n","\t Val. Loss: 0.556 |  Val. Acc: 70.56%\n","Epoch: 02 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.555 | Train Acc: 70.35%\n","\t Val. Loss: 0.533 |  Val. Acc: 72.52%\n","Epoch: 03 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.538 | Train Acc: 71.95%\n","\t Val. Loss: 0.527 |  Val. Acc: 72.80%\n","Epoch: 04 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.527 | Train Acc: 72.74%\n","\t Val. Loss: 0.518 |  Val. Acc: 73.46%\n","Epoch: 05 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.515 | Train Acc: 73.74%\n","\t Val. Loss: 0.515 |  Val. Acc: 73.90%\n","Epoch: 06 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.509 | Train Acc: 74.23%\n","\t Val. Loss: 0.519 |  Val. Acc: 73.34%\n","Epoch: 07 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.499 | Train Acc: 74.74%\n","\t Val. Loss: 0.515 |  Val. Acc: 74.08%\n","Epoch: 08 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.494 | Train Acc: 75.10%\n","\t Val. Loss: 0.510 |  Val. Acc: 73.98%\n","Epoch: 09 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.487 | Train Acc: 75.86%\n","\t Val. Loss: 0.517 |  Val. Acc: 74.22%\n","Epoch: 10 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.483 | Train Acc: 76.01%\n","\t Val. Loss: 0.509 |  Val. Acc: 74.58%\n","Epoch: 11 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.477 | Train Acc: 76.31%\n","\t Val. Loss: 0.535 |  Val. Acc: 74.14%\n","Epoch: 12 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.474 | Train Acc: 76.70%\n","\t Val. Loss: 0.512 |  Val. Acc: 74.72%\n","Epoch: 13 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.468 | Train Acc: 76.86%\n","\t Val. Loss: 0.526 |  Val. Acc: 74.15%\n","Epoch: 14 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.464 | Train Acc: 77.16%\n","\t Val. Loss: 0.514 |  Val. Acc: 74.51%\n","Epoch: 15 | Epoch Time: 1m 14s\n","\tTrain Loss: 0.461 | Train Acc: 77.31%\n","\t Val. Loss: 0.517 |  Val. Acc: 73.67%\n","Epoch: 16 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.456 | Train Acc: 77.81%\n","\t Val. Loss: 0.516 |  Val. Acc: 74.23%\n","Epoch: 17 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.452 | Train Acc: 78.07%\n","\t Val. Loss: 0.518 |  Val. Acc: 74.31%\n","Epoch: 18 | Epoch Time: 1m 13s\n","\tTrain Loss: 0.448 | Train Acc: 78.27%\n","\t Val. Loss: 0.529 |  Val. Acc: 73.89%\n","Epoch: 19 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.444 | Train Acc: 78.50%\n","\t Val. Loss: 0.530 |  Val. Acc: 73.95%\n","Epoch: 20 | Epoch Time: 1m 15s\n","\tTrain Loss: 0.443 | Train Acc: 78.54%\n","\t Val. Loss: 0.515 |  Val. Acc: 74.10%\n"]}],"source":["N_EPOCHS = 20\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, False)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, False)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), f'./Reddit Data/model/finbert-model.pt')\n","    #else:\n","    #break #early stop\n","\n","    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"erM_BUMWwmXa","outputId":"2f6fd6b3-8439-40a3-f986-a339b724c1f1"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7329915364583334, 'precision': 0.7590314391720367, 'recall': 0.6550387596899225, 'f1': 0.7032112166440525, 'matthews_corr': 0.4670812079389918}\n"]}],"source":["y_pred, y_pred_prob, y_true = predict(model, test_iterator, False)\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"yOzcE3vHwmXa","outputId":"1789bb06-b3fb-41ee-9aa0-d9fa92b0f194"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["evaluation_dict['FinBERT'] = [metrics, y_pred, y_true]"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"N4IpMq3OwmXa"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.739013671875, 'precision': 0.7484964461454346, 'recall': 0.69211324570273, 'f1': 0.7192014709745206, 'matthews_corr': 0.47738698123347867}\n"]}],"source":["model.load_state_dict(torch.load('./Reddit Data/model/finbert-model.pt'))\n","\n","y_pred, y_pred_prob, y_true = predict(model, test_iterator, False)\n","\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","evaluation_dict['FinBERT'] = [metrics, y_pred, y_pred_prob,y_true]\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"jTueAePIwmXa","outputId":"2405b475-0e7f-469b-f755-5e191a6cb70e"}},{"cell_type":"markdown","source":["BART"],"metadata":{"collapsed":false,"id":"JWtx-78XwmXa"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"u4N-zc3AwmXb"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["0 2 1 3\n"]}],"source":["max_input_length=tokenizer.max_model_input_sizes[\"facebook/bart-base\"]\n","init_token_idx = tokenizer.cls_token_id\n","eos_token_idx = tokenizer.sep_token_id\n","pad_token_idx = tokenizer.pad_token_id\n","unk_token_idx = tokenizer.unk_token_id\n","print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"VKy8otJVwmXb","outputId":"57de1f4e-35fd-4610-9f6a-69755109d596"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': 1, 'text': [31653, 885, 37844, 919, 46223, 428, 946, 1597, 3068, 14131, 48288, 118, 721, 3369, 705, 821, 1794, 524, 438, 295, 1638]}\n"]}],"source":["TEXT = data.Field(batch_first=True,\n","                  use_vocab=False,\n","                  tokenize=tokenize_and_cut,\n","                  preprocessing=tokenizer.convert_tokens_to_ids,\n","                  init_token=init_token_idx,\n","                  eos_token=eos_token_idx,\n","                  pad_token=pad_token_idx,\n","                  unk_token=unk_token_idx)\n","\n","LABEL = data.LabelField(dtype=torch.float, use_vocab=False, preprocessing=int)\n","fields = [(\"label\", LABEL), (\"text\", TEXT)]\n","train_data, valid_data, test_data = data.TabularDataset.splits(\n","    path=file_p, train='train.csv',\n","    validation='valid.csv',\n","    test='test.csv',\n","    format='csv', skip_header=True, fields=fields)\n","print(vars(test_data.examples[30]))\n","LABEL.build_vocab(train_data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"LLOCLUWCwmXc","outputId":"1cc98ed8-4c5f-45fe-d9da-04be8f56c033"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["BATCH_SIZE = 32\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    sort_key=lambda x: len(x.text),\n","    sort_within_batch=True,\n","    device=device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"5XRkbVNqwmXd"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","model = TransformerGRU('bart',\n","                       HIDDEN_DIM,\n","                       OUTPUT_DIM,\n","                       N_LAYERS,\n","                       BIDIRECTIONAL,\n","                       DROPOUT)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"IR6UZPEHwmXe"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 142,179,585 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"TPpOjyzkwmXe","outputId":"112f2071-39e3-4a99-b47b-93d186c9000e"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 2,759,169 trainable parameters\n"]}],"source":["for name, param in model.named_parameters():\n","    if name.startswith('nlp'):\n","        param.requires_grad = False\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"MHPq-rsFwmXf","outputId":"a038b0eb-e803-4df3-a742-0dbdd1b8c9e8"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"goMbw9uswmXf"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 01 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.578 | Train Acc: 68.73%\n","\t Val. Loss: 0.519 |  Val. Acc: 73.43%\n","Epoch: 02 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.548 | Train Acc: 71.20%\n","\t Val. Loss: 0.510 |  Val. Acc: 74.17%\n","Epoch: 03 | Epoch Time: 1m 29s\n","\tTrain Loss: 0.537 | Train Acc: 72.19%\n","\t Val. Loss: 0.507 |  Val. Acc: 74.45%\n","Epoch: 04 | Epoch Time: 1m 29s\n","\tTrain Loss: 0.534 | Train Acc: 72.54%\n","\t Val. Loss: 0.503 |  Val. Acc: 74.69%\n","Epoch: 05 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.530 | Train Acc: 72.76%\n","\t Val. Loss: 0.501 |  Val. Acc: 74.90%\n","Epoch: 06 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.528 | Train Acc: 72.83%\n","\t Val. Loss: 0.508 |  Val. Acc: 74.50%\n","Epoch: 07 | Epoch Time: 1m 27s\n","\tTrain Loss: 0.524 | Train Acc: 73.27%\n","\t Val. Loss: 0.504 |  Val. Acc: 74.79%\n","Epoch: 08 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.523 | Train Acc: 73.18%\n","\t Val. Loss: 0.499 |  Val. Acc: 75.08%\n","Epoch: 09 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.522 | Train Acc: 73.25%\n","\t Val. Loss: 0.499 |  Val. Acc: 74.98%\n","Epoch: 10 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.522 | Train Acc: 73.42%\n","\t Val. Loss: 0.500 |  Val. Acc: 75.20%\n","Epoch: 11 | Epoch Time: 1m 29s\n","\tTrain Loss: 0.520 | Train Acc: 73.59%\n","\t Val. Loss: 0.502 |  Val. Acc: 74.51%\n","Epoch: 12 | Epoch Time: 1m 29s\n","\tTrain Loss: 0.520 | Train Acc: 73.42%\n","\t Val. Loss: 0.503 |  Val. Acc: 75.05%\n","Epoch: 13 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.518 | Train Acc: 73.80%\n","\t Val. Loss: 0.500 |  Val. Acc: 75.09%\n","Epoch: 14 | Epoch Time: 1m 29s\n","\tTrain Loss: 0.517 | Train Acc: 73.72%\n","\t Val. Loss: 0.501 |  Val. Acc: 74.60%\n","Epoch: 15 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.516 | Train Acc: 73.72%\n","\t Val. Loss: 0.499 |  Val. Acc: 74.83%\n","Epoch: 16 | Epoch Time: 1m 29s\n","\tTrain Loss: 0.517 | Train Acc: 73.71%\n","\t Val. Loss: 0.498 |  Val. Acc: 74.87%\n","Epoch: 17 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.515 | Train Acc: 73.91%\n","\t Val. Loss: 0.497 |  Val. Acc: 75.33%\n","Epoch: 18 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.517 | Train Acc: 73.67%\n","\t Val. Loss: 0.497 |  Val. Acc: 75.05%\n","Epoch: 19 | Epoch Time: 1m 29s\n","\tTrain Loss: 0.514 | Train Acc: 73.98%\n","\t Val. Loss: 0.500 |  Val. Acc: 74.61%\n","Epoch: 20 | Epoch Time: 1m 28s\n","\tTrain Loss: 0.516 | Train Acc: 73.92%\n","\t Val. Loss: 0.500 |  Val. Acc: 75.06%\n"]}],"source":["N_EPOCHS = 20\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, False)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, False)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), f'./Reddit Data/model/bart-model.pt')\n","    #else:\n","    #break #early stop\n","\n","    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"06P5dW9KwmXf","outputId":"00d49a15-f7a6-4738-ffa9-338776bdc0c8"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.75048828125, 'precision': 0.7727272727272727, 'recall': 0.6846983485001685, 'f1': 0.7260543245175125, 'matthews_corr': 0.5015803174427628}\n"]}],"source":["model.load_state_dict(torch.load('./Reddit Data/model/bart-model.pt'))\n","y_pred, y_pred_prob, y_true = predict(model, test_iterator, False)\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","print(metrics)\n","evaluation_dict['BART'] = [metrics, y_pred, y_pred_prob, y_true]"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"IFLX84t1wmXg","outputId":"e548a25f-30f6-42c7-db9d-02d403bbf6d6"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.7464192708333334, 'precision': 0.7845315024232633, 'recall': 0.6547017189079879, 'f1': 0.7137607936799558, 'matthews_corr': 0.49591421484603343}\n"]}],"source":["y_pred, y_pred_prob, y_true = predict(model, test_iterator, False)\n","metrics = get_evaluation_metrics(y_true, y_pred)\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"3FE4s-_HwmXg","outputId":"a2a381ec-f079-4cef-fbd8-024997e84158"}},{"cell_type":"code","source":["import pandas as pd\n","output_list=[]\n","for k,v in evaluation_dict.items():\n","    a_tuple=(k,v[0]['accuracy'],v[0]['precision'],v[0]['recall'],v[0]['f1'],v[0]['matthews_corr'],list(v[1]),list(v[2]),list(v[3]))\n","    output_list.append(a_tuple)\n","\n","output_pd=pd.DataFrame.from_records(output_list,columns=['encode_algo','accuracy','precision','recall','f1','matthews_corr','y_pred','y_pred_prob','y_true'])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"LaXCPB16wmXh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"       encode_algo  accuracy  precision    recall        f1  matthews_corr  \\\n0  word2vec+BiLSTM  0.766195   0.776813  0.723795  0.749368       0.531949   \n1   word2vec+BiGRU  0.767904   0.792632  0.703404  0.745357       0.536742   \n2     word2vec+CNN  0.748414   0.776918  0.680088  0.725285       0.498854   \n3     glove+BiLSTM  0.770508   0.806858  0.689922  0.743823       0.543684   \n4      glove+BiGRU  0.769694   0.771424  0.743343  0.757123       0.538628   \n5        glove+CNN  0.759138   0.750952  0.758236  0.754576       0.518144   \n\n                                              y_pred  \\\n0  [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n2  [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n3  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...   \n4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...   \n5  [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...   \n\n                                         y_pred_prob  \\\n0  [0.25730207562446594, 0.3950068950653076, 0.52...   \n1  [0.23041464388370514, 0.406343936920166, 0.405...   \n2  [0.19342537224292755, 0.39263078570365906, 0.0...   \n3  [0.20228347182273865, 0.464068204164505, 0.397...   \n4  [0.31738635897636414, 0.4710213840007782, 0.35...   \n5  [0.4731840193271637, 0.05732743442058563, 0.45...   \n\n                                              y_true  \n0  [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n1  [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n2  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...  \n3  [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n4  [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n5  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encode_algo</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>matthews_corr</th>\n      <th>y_pred</th>\n      <th>y_pred_prob</th>\n      <th>y_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>word2vec+BiLSTM</td>\n      <td>0.766195</td>\n      <td>0.776813</td>\n      <td>0.723795</td>\n      <td>0.749368</td>\n      <td>0.531949</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n      <td>[0.25730207562446594, 0.3950068950653076, 0.52...</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>word2vec+BiGRU</td>\n      <td>0.767904</td>\n      <td>0.792632</td>\n      <td>0.703404</td>\n      <td>0.745357</td>\n      <td>0.536742</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>[0.23041464388370514, 0.406343936920166, 0.405...</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>word2vec+CNN</td>\n      <td>0.748414</td>\n      <td>0.776918</td>\n      <td>0.680088</td>\n      <td>0.725285</td>\n      <td>0.498854</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.19342537224292755, 0.39263078570365906, 0.0...</td>\n      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>glove+BiLSTM</td>\n      <td>0.770508</td>\n      <td>0.806858</td>\n      <td>0.689922</td>\n      <td>0.743823</td>\n      <td>0.543684</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n      <td>[0.20228347182273865, 0.464068204164505, 0.397...</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>glove+BiGRU</td>\n      <td>0.769694</td>\n      <td>0.771424</td>\n      <td>0.743343</td>\n      <td>0.757123</td>\n      <td>0.538628</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n      <td>[0.31738635897636414, 0.4710213840007782, 0.35...</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>glove+CNN</td>\n      <td>0.759138</td>\n      <td>0.750952</td>\n      <td>0.758236</td>\n      <td>0.754576</td>\n      <td>0.518144</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>[0.4731840193271637, 0.05732743442058563, 0.45...</td>\n      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":150,"metadata":{},"output_type":"execute_result"}],"source":["output_pd"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"GDvHCVfxwmXi","outputId":"31962364-0fd6-4e52-81bd-0e186219c6a4"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["output_pd.to_csv('./Reddit Data/evaluations_dp.csv',index=False)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"DKPWygafwmXi"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import pandas as pd\n","output_list=[]\n","for k,v in evaluation_dict.items():\n","    a_tuple=(k,v[0]['accuracy'],v[0]['precision'],v[0]['recall'],v[0]['f1'],v[0]['matthews_corr'],list(v[1]),list(v[2]),list(v[3]))\n","    output_list.append(a_tuple)\n","\n","output_pd=pd.DataFrame.from_records(output_list,columns=['encode_algo','accuracy','precision','recall','f1','matthews_corr','y_pred','y_pred_prob','y_true'])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Y0W8bOjnwmXj"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"  encode_algo  accuracy  precision    recall        f1  matthews_corr  \\\n0     RoBERTa  0.749105   0.773032  0.680148  0.723622       0.499026   \n1     FinBERT  0.739014   0.748496  0.692113  0.719201       0.477387   \n2        BART  0.750488   0.772727  0.684698  0.726054       0.501580   \n\n                                              y_pred  \\\n0  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...   \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                         y_pred_prob  \\\n0  [0.14009037613868713, 0.14009037613868713, 0.4...   \n1  [0.19639503955841064, 0.43970686197280884, 0.1...   \n2  [0.17646411061286926, 0.17646411061286926, 0.3...   \n\n                                              y_true  \n0  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, ...  \n2  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encode_algo</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>matthews_corr</th>\n      <th>y_pred</th>\n      <th>y_pred_prob</th>\n      <th>y_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RoBERTa</td>\n      <td>0.749105</td>\n      <td>0.773032</td>\n      <td>0.680148</td>\n      <td>0.723622</td>\n      <td>0.499026</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n      <td>[0.14009037613868713, 0.14009037613868713, 0.4...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FinBERT</td>\n      <td>0.739014</td>\n      <td>0.748496</td>\n      <td>0.692113</td>\n      <td>0.719201</td>\n      <td>0.477387</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.19639503955841064, 0.43970686197280884, 0.1...</td>\n      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BART</td>\n      <td>0.750488</td>\n      <td>0.772727</td>\n      <td>0.684698</td>\n      <td>0.726054</td>\n      <td>0.501580</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.17646411061286926, 0.17646411061286926, 0.3...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["output_pd"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"r4yVv9DVwmXj","outputId":"76a10548-aab3-48a1-dcb5-18bb99973c17"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["output_pd.to_csv('./Reddit Data/evaluations_transformer.csv',index=False)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"01v6u03kwmXj"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"IUmR4H11wmXk"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"uC9WZ-fNwmXk"}},{"cell_type":"markdown","source":["Fine-Tuning BERT and FinBERT over Google Collab, download the fine-tune results and perform evluation analysis\n","These codes are adopted from https://skimai.com/fine-tuning-bert-for-sentiment-analysis/"],"metadata":{"id":"azOY6tCix7zJ"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from transformers import BertTokenizer\n","# Load the BERT tokenizer\n","#tokenizer=AutoTokenizer.from_pretrained(\"ProsusAI/finbert\",do_lower_case=True)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"f18GMjyEwmXk"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import torch\n","# Create a function to tokenize a set of texts\n","def preprocessing_for_bert(data):\n","    \"\"\"Perform required preprocessing steps for pretrained BERT.\n","    @param    data (np.array): Array of texts to be processed.\n","    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n","    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n","                  tokens should be attended to by the model.\n","    \"\"\"\n","    # Create empty lists to store outputs\n","    input_ids = []\n","    attention_masks = []\n","\n","    # For every sentence...\n","    for sent in data:\n","        # `encode_plus` will:\n","        #    (1) Tokenize the sentence\n","        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n","        #    (3) Truncate/Pad sentence to max length\n","        #    (4) Map tokens to their IDs\n","        #    (5) Create attention mask\n","        #    (6) Return a dictionary of outputs\n","        encoded_sent = tokenizer.encode_plus(\n","            text=sent,  # Preprocess sentence\n","            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n","            padding='max_length',\n","            truncation=True,# Pad sentence to max length\n","            #return_tensors='pt',           # Return PyTorch tensor\n","            return_attention_mask=True      # Return attention mask\n","            )\n","\n","        # Add the outputs to the lists\n","        input_ids.append(encoded_sent.get('input_ids'))\n","        attention_masks.append(encoded_sent.get('attention_mask'))\n","\n","    # Convert lists to tensors\n","    input_ids = torch.tensor(input_ids)\n","    attention_masks = torch.tensor(attention_masks)\n","\n","    return input_ids, attention_masks"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"dHH2dXw3wmXk"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"WGMAXOPBwmXl"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","train_data=pd.read_csv('./Reddit Data/train.csv')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"b0L1epnpwmXl"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"   Label_encode                                          Full_stem\n0             1                                  5 year learn curv\n1             0                         tank speak upside-down_fac\n2             1  sos almost 60 float short guy want fight back ...\n3             1         good friday everyon 's week 's haul week 2\n4             0  40 sqqq retard hold sqqq right 'm 40 lmfao 'm ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label_encode</th>\n      <th>Full_stem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5 year learn curv</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>tank speak upside-down_fac</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>sos almost 60 float short guy want fight back ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>good friday everyon 's week 's haul week 2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>40 sqqq retard hold sqqq right 'm 40 lmfao 'm ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"XdnRnLijwmXl","outputId":"4ef685c4-672f-4de5-ab86-06332515e303"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["valid_data=pd.read_csv('./Reddit Data/valid.csv')\n","test_data=pd.read_csv('./Reddit Data/test.csv')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"ide1KDUFwmXm"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (980 > 512). Running this sequence through the model will result in indexing errors\n"]},{"name":"stdout","output_type":"stream","text":["Max length:  980\n"]}],"source":["# Concatenate train data and test data\n","all_posts = np.concatenate([train_data.Full_stem.values, valid_data.Full_stem.values,test_data.Full_stem.values])\n","\n","# Encode our concatenated data\n","encoded_posts = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_posts]\n","\n","# Find the maximum length\n","max_len = max([len(sent) for sent in encoded_posts])\n","print('Max length: ', max_len)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"TQifLFN8wmXm","outputId":"edc0c7b5-c9fc-4fd3-f00c-a532f0fb877f"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X = train_data.Full_stem.values\n","y = train_data.Label_encode.values\n","X_train, X_val, y_train, y_val=train_test_split(X, y, test_size=0.1, random_state=2020)\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"23J_Clu4wmXm"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"numpy.ndarray"},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["type(X_train)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Zp7_qbGPwmXn","outputId":"b3961c2b-f08a-48b5-9875-1ea15d5307ea"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"array(['5 year learn curv', 'tank speak upside-down_fac',\n       'sos almost 60 float short guy want fight back hedgi one best bet share price low 2.30 float 46m revenu growth 1700 morgan stanley own 1m share rough 4.5',\n       ...,\n       'assign share sold cash cover put account buy power show negat mistak robin hood money somehow even cash account refer',\n       'sign god rocket rocket rocket rocket rocket rocket rocket rocket rocket rocket rocket gem_ston open_hand delet',\n       \"miss go movi thought 'd put would spent popcorn\"], dtype=object)"},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["np.asarray(train_data.Full_stem.values)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"1u-YEL07wmXn","outputId":"da82bb62-4378-4a47-8dc4-0f3838be6194"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["X_train=np.asarray(train_data.Full_stem.values)\n","y_train=np.asarray(train_data.Label_encode.values)\n","X_valid=np.asarray(valid_data.Full_stem.values)\n","y_valid=np.asarray(valid_data.Label_encode.values)\n","X_test=np.asarray(test_data.Full_stem.values)\n","y_test=np.asarray(test_data.Label_encode.values)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"QFTVhIJ9wmXo"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Original:  5 year learn curv\n","Token IDs:  [101, 1019, 2095, 4553, 12731, 2099, 2615, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Tracy\\PycharmProjects\\FIT9136\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["# Specify `MAX_LEN`\n","MAX_LEN = 512\n","\n","# Print sentence 0 and its encoded token ids\n","token_ids = list(preprocessing_for_bert([X_train[0]])[0].squeeze().numpy())\n","print('Original: ', X_train[0])\n","print('Token IDs: ', token_ids)\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"BQ6BSgjqwmXp","outputId":"b0baedb1-7f35-478b-9d56-1792ce3610c3"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenizing data...\n"]}],"source":["\n","# Run function `preprocessing_for_bert` on the train set and the validation set\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(X_train)\n","valid_inputs, valid_masks = preprocessing_for_bert(X_valid)\n","test_inputs,test_masks=preprocessing_for_bert(X_test)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"H_KQVntXwmXp","outputId":"b0279f90-fa40-4e15-d8d2-786931ddb2fb"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train)\n","valid_labels = torch.tensor(y_valid)\n","test_labels = torch.tensor(y_test)\n","\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 8\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","valid_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\n","valid_sampler = SequentialSampler(valid_data)\n","valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"viXIaFUiwmXp"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Wall time: 0 ns\n"]}],"source":["%%time\n","import torch\n","import torch.nn as nn\n","from transformers import AutoModel\n","from transformers import BertModel\n","# Create the BertClassfier class\n","class BertClassifier(nn.Module):\n","    \"\"\"Bert Model for Classification Tasks.\n","    \"\"\"\n","    def __init__(self, freeze_bert=False):\n","        \"\"\"\n","        @param    bert: a BertModel object\n","        @param    classifier: a torch.nn.Module classifier\n","        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n","        \"\"\"\n","        super(BertClassifier, self).__init__()\n","        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n","        D_in, H, D_out = 768, 50, 2\n","\n","        # Instantiate BERT model\n","        #self.bert = AutoModel.from_pretrained(\"ProsusAI/finbert\")\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","\n","\n","        # Instantiate an one-layer feed-forward classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(D_in, H),\n","            nn.ReLU(),\n","            #nn.Dropout(0.5),\n","            nn.Linear(H, D_out)\n","        )\n","\n","        # Freeze the BERT model\n","        if freeze_bert:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, input_ids, attention_mask):\n","        \"\"\"\n","        Feed input to BERT and the classifier to compute logits.\n","        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n","                      max_length)\n","        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n","                      information with shape (batch_size, max_length)\n","        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n","                      num_labels)\n","        \"\"\"\n","        # Feed input to BERT\n","        outputs = self.bert(input_ids=input_ids,\n","                            attention_mask=attention_mask)\n","\n","        # Extract the last hidden state of the token `[CLS]` for classification task\n","        last_hidden_state_cls = outputs[0][:, 0, :]\n","\n","        # Feed input to classifier to compute logits\n","        logits = self.classifier(last_hidden_state_cls)\n","\n","        return logits"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"rVQKMtfIwmXq","outputId":"f1e5b3de-ff91-4430-de96-285bb71491bb"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from transformers import get_linear_schedule_with_warmup\n","from torch.optim import AdamW\n","def initialize_model(epochs=3):\n","    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n","    \"\"\"\n","    # Instantiate Bert Classifier\n","    bert_classifier = BertClassifier(freeze_bert=False)\n","\n","    # Tell PyTorch to run the model on GPU\n","    bert_classifier.to(device)\n","\n","    # Create the optimizer\n","    optimizer = AdamW(bert_classifier.parameters(),\n","                      lr=5e-5,    # Default learning rate\n","                      )\n","\n","    # Total number of training steps\n","    total_steps = len(train_dataloader) * epochs\n","\n","    # Set up the learning rate scheduler\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0, # Default value\n","                                                num_training_steps=total_steps)\n","    return bert_classifier, optimizer, scheduler"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"HgvI4bRvwmXr"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import random\n","import time\n","\n","# Specify loss function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def set_seed(seed_value=1234):\n","    \"\"\"Set seed for reproducibility.\n","    \"\"\"\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","\n","def train(model, train_dataloader, val_dataloader=None, epochs=3, evaluation=False):\n","    \"\"\"Train the BertClassifier model.\n","    \"\"\"\n","    # Start training loop\n","    print(\"Start training...\\n\")\n","    for epoch_i in range(epochs):\n","        # =======================================\n","        #               Training\n","        # =======================================\n","        # Print the header of the result table\n","        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n","        print(\"-\"*70)\n","\n","        # Measure the elapsed time of each epoch\n","        t0_epoch, t0_batch = time.time(), time.time()\n","\n","        # Reset tracking variables at the beginning of each epoch\n","        total_loss, batch_loss, batch_counts = 0, 0, 0\n","\n","        # Put the model into the training mode\n","        model.train()\n","\n","        # For each batch of training data...\n","        for step, batch in enumerate(train_dataloader):\n","            batch_counts +=1\n","            # Load batch to GPU\n","            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","            # Zero out any previously calculated gradients\n","            model.zero_grad()\n","\n","            # Perform a forward pass. This will return logits.\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","            # Compute loss and accumulate the loss values\n","            loss = loss_fn(logits, b_labels)\n","            batch_loss += loss.item()\n","            total_loss += loss.item()\n","\n","            # Perform a backward pass to calculate gradients\n","            loss.backward()\n","\n","            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            # Update parameters and the learning rate\n","            optimizer.step()\n","            scheduler.step()\n","\n","            # Print the loss values and time elapsed for every 20 batches\n","            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n","                # Calculate time elapsed for 20 batches\n","                time_elapsed = time.time() - t0_batch\n","\n","                # Print training results\n","                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n","\n","                # Reset batch tracking variables\n","                batch_loss, batch_counts = 0, 0\n","                t0_batch = time.time()\n","\n","        # Calculate the average loss over the entire training data\n","        avg_train_loss = total_loss / len(train_dataloader)\n","\n","        print(\"-\"*70)\n","        # =======================================\n","        #               Evaluation\n","        # =======================================\n","        if evaluation == True:\n","            # After the completion of each training epoch, measure the model's performance\n","            # on our validation set.\n","            val_loss, val_accuracy = evaluate(model, val_dataloader)\n","\n","            # Print performance over the entire training data\n","            time_elapsed = time.time() - t0_epoch\n","\n","            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n","            print(\"-\"*70)\n","        print(\"\\n\")\n","\n","    print(\"Training complete!\")\n","\n","\n","def evaluate(model, val_dataloader):\n","    \"\"\"After the completion of each training epoch, measure the model's performance\n","    on our validation set.\n","    \"\"\"\n","    # Put the model into the evaluation mode. The dropout layers are disabled during\n","    # the test time.\n","    model.eval()\n","\n","    # Tracking variables\n","    val_accuracy = []\n","    val_loss = []\n","\n","    # For each batch in our validation set...\n","    for batch in val_dataloader:\n","        # Load batch to GPU\n","        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","        # Compute logits\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","        # Compute loss\n","        loss = loss_fn(logits, b_labels)\n","        val_loss.append(loss.item())\n","\n","        # Get the predictions\n","        preds = torch.argmax(logits, dim=1).flatten()\n","\n","        # Calculate the accuracy rate\n","        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n","        val_accuracy.append(accuracy)\n","\n","    # Compute the average accuracy and loss over the validation set.\n","    val_loss = np.mean(val_loss)\n","    val_accuracy = np.mean(val_accuracy)\n","\n","    return val_loss, val_accuracy"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"5ZxnWVmmwmXr"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["device = torch.device('cpu')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"4uD3XEokwmXs"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"rkp6eZ9owmXt"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"device(type='cpu')"},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["device"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"b5D22y2CwmXt","outputId":"53173821-9eb3-46e6-bcb2-56465d53873a"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["set_seed(1234)    # Set seed for reproducibility\n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n","#train(bert_classifier, train_dataloader, valid_dataloader, epochs=2, evaluation=True)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"l5qi6n7gwmXt","outputId":"419a85dd-5f00-4931-b103-65145f1e1602"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["# load the model\n","import torch\n","checkpoint = torch.load('C:/Users/Tracy/Downloads/finbert_model.pth', map_location='cpu')\n","bert_classifier.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"G6RsrnIOwmX3"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["checkpoint = torch.load('C:/Users/Tracy/Downloads/bert_model.pth', map_location='cpu')\n","bert_classifier.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"4Nrte08ywmX3"}},{"cell_type":"markdown","source":["Evaluations"],"metadata":{"id":"WLaonRfmy4J1"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import os\n","import re\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Of9d6R3dwmX0"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import torch.nn.functional as F\n","\n","def bert_predict(model, test_dataloader):\n","    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n","    on the test set.\n","    \"\"\"\n","    # Put the model into the evaluation mode. The dropout layers are disabled during\n","    # the test time.\n","    model.eval()\n","\n","    all_logits = []\n","\n","    # For each batch in our test set...\n","    for batch in test_dataloader:\n","        # Load batch to GPU\n","        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n","\n","        # Compute logits\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","        all_logits.append(logits)\n","\n","    # Concatenate logits from each batch\n","    all_logits = torch.cat(all_logits, dim=0)\n","\n","    # Apply softmax to calculate probabilities\n","    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n","\n","    return probs"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"gI0IoeGrwmX1"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from sklearn.metrics import accuracy_score, roc_curve, auc\n","\n","def evaluate_roc(probs, y_true):\n","    \"\"\"\n","    - Print AUC and accuracy on the test set\n","    - Plot ROC\n","    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n","    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n","    \"\"\"\n","    preds = probs[:, 1]\n","    fpr, tpr, threshold = roc_curve(y_true, preds)\n","    roc_auc = auc(fpr, tpr)\n","    print(f'AUC: {roc_auc:.4f}')\n","\n","    # Get accuracy over the test set\n","    y_pred = np.where(preds >= 0.5, 1, 0)\n","    accuracy = accuracy_score(y_true, y_pred)\n","    print(f'Accuracy: {accuracy*100:.2f}%')\n","    return y_pred"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"csxmhDAFwmX1"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["# Compute predicted probabilities on the test set\n","probs_bert = bert_predict(bert_classifier, test_dataloader)\n","\n","# Evaluate the Bert classifier\n","#evaluate_roc(probs, y_val)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"2sR5o7x1wmX1"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["AUC: 0.8699\n","Accuracy: 78.56%\n"]},{"data":{"text/plain":"array([0, 0, 1, ..., 1, 0, 1])"},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["evaluate_roc(probs_bert,y_test)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"93MUmScVwmX1","outputId":"cbc8e183-4526-4c8e-81f4-49825819cd2e"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["dp=pd.read_csv('./Reddit Data/evaluations_dp.csv')\n","transformer=pd.read_csv('./Reddit Data/evaluations_transformer.csv')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"aUTQIW2OwmX2"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"       encode_algo  accuracy  precision    recall        f1  matthews_corr  \\\n0  word2vec+BiLSTM  0.766195   0.776813  0.723795  0.749368       0.531949   \n1   word2vec+BiGRU  0.767904   0.792632  0.703404  0.745357       0.536742   \n2     word2vec+CNN  0.748414   0.776918  0.680088  0.725285       0.498854   \n3     glove+BiLSTM  0.770508   0.806858  0.689922  0.743823       0.543684   \n4      glove+BiGRU  0.769694   0.771424  0.743343  0.757123       0.538628   \n5        glove+CNN  0.759138   0.750952  0.758236  0.754576       0.518144   \n\n                                              y_pred  \\\n0  [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n2  [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n3  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...   \n4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...   \n5  [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...   \n\n                                         y_pred_prob  \\\n0  [0.25730207562446594, 0.3950068950653076, 0.52...   \n1  [0.23041464388370514, 0.406343936920166, 0.405...   \n2  [0.19342537224292755, 0.39263078570365906, 0.0...   \n3  [0.20228347182273865, 0.464068204164505, 0.397...   \n4  [0.31738635897636414, 0.4710213840007782, 0.35...   \n5  [0.4731840193271637, 0.05732743442058563, 0.45...   \n\n                                              y_true  \n0  [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n1  [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n2  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...  \n3  [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n4  [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n5  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encode_algo</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>matthews_corr</th>\n      <th>y_pred</th>\n      <th>y_pred_prob</th>\n      <th>y_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>word2vec+BiLSTM</td>\n      <td>0.766195</td>\n      <td>0.776813</td>\n      <td>0.723795</td>\n      <td>0.749368</td>\n      <td>0.531949</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n      <td>[0.25730207562446594, 0.3950068950653076, 0.52...</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>word2vec+BiGRU</td>\n      <td>0.767904</td>\n      <td>0.792632</td>\n      <td>0.703404</td>\n      <td>0.745357</td>\n      <td>0.536742</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>[0.23041464388370514, 0.406343936920166, 0.405...</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>word2vec+CNN</td>\n      <td>0.748414</td>\n      <td>0.776918</td>\n      <td>0.680088</td>\n      <td>0.725285</td>\n      <td>0.498854</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.19342537224292755, 0.39263078570365906, 0.0...</td>\n      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>glove+BiLSTM</td>\n      <td>0.770508</td>\n      <td>0.806858</td>\n      <td>0.689922</td>\n      <td>0.743823</td>\n      <td>0.543684</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n      <td>[0.20228347182273865, 0.464068204164505, 0.397...</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>glove+BiGRU</td>\n      <td>0.769694</td>\n      <td>0.771424</td>\n      <td>0.743343</td>\n      <td>0.757123</td>\n      <td>0.538628</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n      <td>[0.31738635897636414, 0.4710213840007782, 0.35...</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>glove+CNN</td>\n      <td>0.759138</td>\n      <td>0.750952</td>\n      <td>0.758236</td>\n      <td>0.754576</td>\n      <td>0.518144</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>[0.4731840193271637, 0.05732743442058563, 0.45...</td>\n      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["dp"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"-bbRVlQ7wmX2","outputId":"e684f587-cd76-4788-fb5c-49116d3d8728"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["y_prob_bert=probs_bert[:,1]"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"0mTj3iXuwmX1"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["y_prob_finbert=probs[:,1]\n","y_true_finbert=y_test"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"KWg3gA3PwmX2"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["y_prob_finbert"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Q7-RBgCxwmX2"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["a_df=pd.DataFrame([y_test.tolist(),probs[:,1]])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Qp7Bh6BLwmX2"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"<Figure size 864x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["from sklearn.metrics import accuracy_score, roc_curve, auc\n","plt.figure(figsize=(12,10))\n","\n","fpr_bert, tpr_bert, threshold = roc_curve(y_test, y_prob_bert)\n","roc_auc_bert = auc(fpr_bert, tpr_bert)\n","plt.plot(fpr_bert, tpr_bert, 'orange', label = 'BERT, AUC = %0.2f' % roc_auc_bert)\n","\n","fpr_finbert, tpr_finbert, threshold = roc_curve(y_test, y_prob_finbert)\n","roc_auc_bert = auc(fpr_finbert, tpr_finbert)\n","plt.plot(fpr_finbert, tpr_finbert, 'brown', label = 'FinBERT, AUC = %0.2f' % roc_auc_bert)\n","\n","fpr_lstm, tpr_lstm, threshold = roc_curve(np.asarray(eval(dp.iloc[3,8])), np.asarray(eval(dp.iloc[3,7])))\n","roc_auc_lstm = auc(fpr_lstm, tpr_lstm)\n","plt.plot(fpr_lstm, tpr_lstm, 'b', label = 'BiLSTM AUC = %0.2f' % roc_auc_lstm)\n","\n","fpr_gru, tpr_gru, threshold = roc_curve(np.asarray(eval(dp.iloc[4,8])), np.asarray(eval(dp.iloc[4,7])))\n","roc_auc_gru = auc(fpr_gru, tpr_gru)\n","plt.plot(fpr_gru, tpr_gru, 'green', label = 'BiGRU, AUC = %0.2f' % roc_auc_gru)\n","\n","fpr_cnn, tpr_cnn, threshold = roc_curve(np.asarray(eval(dp.iloc[5,8])), np.asarray(eval(dp.iloc[5,7])))\n","roc_auc_cnn = auc(fpr_cnn, tpr_cnn)\n","plt.plot(fpr_cnn, tpr_cnn, 'black', label = 'CNN, AUC = %0.2f' % roc_auc_cnn)\n","\n","    # Plot ROC AUC\n","plt.title('Receiver Operating Characteristic Cruve')\n","\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"C7f1WP7zwmX2","outputId":"ea43bd04-b88c-43a7-cc72-37be15a24c5b"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from sklearn.metrics import matthews_corrcoef,accuracy_score,f1_score,precision_score,recall_score\n","def get_evaluation_metrics(y_true,y_pred):\n","    metrics_dict=dict()\n","    metrics_dict['accuracy']=accuracy_score(y_true,y_pred)\n","    metrics_dict['precision']=precision_score(y_true,y_pred)\n","    metrics_dict['recall']=recall_score(y_true,y_pred)\n","    metrics_dict['f1']=f1_score(y_true,y_pred)\n","    metrics_dict['matthews_corr']=matthews_corrcoef(y_true,y_pred)\n","    return metrics_dict"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"v7nZeiNWwmX3"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["AUC: 0.8710\n","Accuracy: 78.38%\n","{'accuracy': 0.7837727864583334, 'precision': 0.7879107362502197, 'recall': 0.7556454330974048, 'f1': 0.7714408602150539, 'matthews_corr': 0.5668988061965222}\n"]}],"source":["y_pred=evaluate_roc(probs,y_test)\n","metrics=get_evaluation_metrics(y_test,y_pred)\n","print(metrics)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Cfw9d2wMwmX3","outputId":"a67dcf00-d041-49cc-804a-e02040f0cd99"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"14Vhyi1NwmX3"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"4vfZvHpxwmX4"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}